{"meta":{"title":"aLong","subtitle":"一个人总是可以善待他毫不在意的人。--王尔德","description":null,"author":"aLong","url":"http://blog.51ai.vip","root":"/"},"pages":[{"title":"关于","date":"2019-03-29T04:30:18.000Z","updated":"2019-08-22T04:10:46.481Z","comments":true,"path":"about/index.html","permalink":"http://blog.51ai.vip/about/index.html","excerpt":"","text":"站点 小站记录信息，写写笔记。之前wordpress搭建的博客意外被黑。数据好在有备份，之后又经历vps被卖家停止，原因是他们不做这生意，他们上级把他们的客户封停了….。 2014年-2018年数据丢失,部分数据有备份,自己太懒了. 后来想想算了，放在GitHub上吧。 个人信息 Name: aLong QQ：604302709 Email：604302709@qq.com"},{"title":"标签","date":"2019-08-22T03:10:58.886Z","updated":"2019-08-22T03:10:58.701Z","comments":true,"path":"tags/index.html","permalink":"http://blog.51ai.vip/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-08-22T03:10:57.256Z","updated":"2019-08-22T03:10:57.137Z","comments":true,"path":"categories/index.html","permalink":"http://blog.51ai.vip/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"网络传输速度测试工具","slug":"网络传输速度测试工具","date":"2019-10-23T09:31:55.000Z","updated":"2019-10-24T05:43:53.213Z","comments":true,"path":"2019/10/23/网络传输速度测试工具/","link":"","permalink":"http://blog.51ai.vip/2019/10/23/网络传输速度测试工具/","excerpt":"","text":"网络传输测试软件 最近公司测试限速,搜集软件发现两款,iperf,LANSpeedTest. iperf,多平台. LANSpeedTest,读写显示,操作简单. 局域网测试传输,优先考虑UDP. iperfIperf可以报告带宽,延迟抖动和数据包丢失.官方文档安装不写了.跳过 iperf常用参数介绍123456789101112 -i 2 #表示每2秒显示一次报告 -w 80k #对于TCP方式，此设置为TCP窗口大小。对于UDP方式，此设置为接受UDP数据包的缓冲区大小，限制可以接受数据包的最大值 -B 192.168.122.1 #绑定到主机的多个地址中的一个。对于客户端来说，这个参数设置了出栈接口。对于服务器端来说，这个参数设置入栈接口。这个参数只用于具有多网络接口的主机。 #在Iperf的UDP模式下，此参数用于绑 定和加入一个多播组。使用范围在224.0.0.0至239.255.255.255的多播地址#常用客户端参数 -b 100m #用于udp测试时，设置测试发送的带宽，单位：bit/秒，不设置时默认为：1Mbit/秒 -c #指定服务端ip地址 -d #同时测试上行和下行 -t 10 #设置传输时间，为10秒 -P 5 #指定发起5个线程 UDP测试123456789服务端 iperf -u -s # -u表示以udp模式运行，-s表示作为服务端, 这里需要设置ip客户端 iperf -u -c 192.168.100.11 -b 100M -t 60 -i 2 #解释：在udp模式下，以100Mbps为数据发送速率，客户端到服务器192.168.100.11上传带宽测试，测试时间为60秒 iperf -u -c 192.168.100.11 5M -P 30 -t 6 #客户端同时向服务器端发起30个连接线程，以5Mbps为数据发送速率 iperf -u -c 192.168.100.11 -b 100M -d -t 60 #以100M为数据发送速率，进行上下行带宽测试 TCP测试1234567服务端 iperf -s客户端 iperf -c 192.168.100.11 -t 60 #在tcp模式下，客户端到服务器192.168.100.11上传带宽测试，测试时间为60秒。 iperf -c 192.168.100.11 -P 30 -t 60 #客户端同时向服务器端发起30个连接线程。 iperf -c 192.168.100.11 -d -t 60 -i 2 #进行上下行带宽测试。 测试结果结果中可以看到:30秒(-t)的测试,传递数据 70+ (-b参数), 监测的带宽约为20M . LANSpeedTest首先server端开启服务即可.LST_Server 程序开启.如图: 终端LAN_SpeedTest 程序.界面如图: 配置种可以配置数据大小:点击Config:具体配置自行参考里面的选项.这里设置10M的数据. 设定好目标IP,Folder or Server IP 这里填写. 单击 Start Test 等待结果. 图为检测中: 结果:检测结果和上面软件类似,约为20M.","categories":[{"name":"soft","slug":"soft","permalink":"http://blog.51ai.vip/categories/soft/"}],"tags":[{"name":"iperf","slug":"iperf","permalink":"http://blog.51ai.vip/tags/iperf/"},{"name":"LANSpeedTest","slug":"LANSpeedTest","permalink":"http://blog.51ai.vip/tags/LANSpeedTest/"}]},{"title":"Prometheus-AlertManager警告管理搭建与配置","slug":"Prometheus-AlertManager警告管理搭建与配置","date":"2019-10-19T01:40:15.000Z","updated":"2019-10-30T02:17:09.145Z","comments":true,"path":"2019/10/19/Prometheus-AlertManager警告管理搭建与配置/","link":"","permalink":"http://blog.51ai.vip/2019/10/19/Prometheus-AlertManager警告管理搭建与配置/","excerpt":"","text":"AlertManager AlertManager处理由客户端应用程序（如Prometheus服务器）发送的警报。它负责重复数据消除、分组，并将它们路由到正确的接收器集成（如电子邮件、PagerDuty或OpsGenie）。它还负责消除和抑制警报。 通过翻译官方文档可以了解到,AlertManager是负责为Prometheus(本身不会发送警报)发送警报的工具.AlertManager不是简单发送警报,可以消除重复警报,分组,抑制警报功能.并支持多接收器. Prometheus-&gt;触发定义的警报规则-&gt;AlertManager-&gt;发送警报到指定通知渠道. 为了能让Prometheus发送警报,我们需要: 搭建AlertManager服务. 定义AlertManager通知配置. 定义Prometheus警报规则并引入. 测试警报. 定义通知模板. 定义AlertManager通知配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 smtp_smarthost: 'smtp.163.com:25' # 邮箱smtp服务器代理 smtp_from: 'shitu-0071@163.com' # 发送邮箱名称 resolve_timeout: 5m # 处理超时时间，默认为5min smtp_auth_username: 'shitu-0071@163.com' # 邮箱帐户 smtp_auth_password: '******' # 邮箱授权码(注意是授权码,不知道自己查一下) wechat_api_url: 'https://qyapi.weixin.qq.com/cgi-bin/' # 企业微信地址# 定义模板信心templates: - 'template/*.tmpl'# 定义路由树信息route: group_by: ['alertname', 'cluster', 'service'] # 报警分组依据 根据标签分组, # 同标签警告会在作为一组警报发送 group_wait: 10s # 最初即第一次等待多久时间发送一组警报的通知 group_interval: 10s # 在发送新警报前的等待时间 repeat_interval: 1m # 发送重复警报的周期 (对于email配置中，此项不可以设置过低，否则将会由于邮件发送太多频繁，被smtp服务器拒绝) receiver: 'email' # 发送警报的接收者的名称， # 以下receivers name的名称 routes: - match: # 普通匹配 serverity: critical # 警告级别critical receiver: email # 通过邮件发送 - match_re: # 正则匹配 severity: ^(warning)$ # 匹配警告级别为warning的 receiver: wechat # 通过微信发送告警 - receiver: along # 定义接收者 match: # 匹配 severity: test # 等级为test # 定义警报接收者信息receivers: - name: 'email' # 警报 email_configs: # 邮箱配置 - to: '******@163.com' # 接收警报的email配置 html: '&#123;&#123; template \"test.html\" . &#125;&#125;' # 设定邮箱的内容模板 headers: &#123; Subject: \"[WARN] 报警邮件\"&#125; # 接收邮件的标题 webhook_configs: # webhook配置 - url: 'http://127.0.0.1:5001' send_resolved: true - name: 'wechat' wechat_configs: # 企业微信报警配置 - send_resolved: true to_party: '1' # 接收组的id agent_id: '1000002' # (企业微信--&gt;自定应用--&gt;AgentId) corp_id: '******' # 企业信息(我的企业--&gt;CorpId[在底部]) api_secret: '******' # 企业微信(企业微信--&gt;自定应用--&gt;Secret) message: '&#123;&#123; template \"test_wechat.html\" . &#125;&#125;' # 发送消息模板的设定# 一个inhibition规则是在与另一组匹配器匹配的警报存在的条件下，# 使匹配一组匹配器的警报失效的规则。两个警报必须具有一组相同的标签。 inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'critical' equal: ['instance'] # 已经发送的告警通知匹配到target_match和target_match_re规则， # 再有新的告警规则如果满足source_match # 或者定义的匹配规则，并且已发送的告警与新产生的告警中equal定义的标签完全相同， # 则启动抑制机制，新的告警不会发送。 以下是官方文档配置翻译的文档.供参考具体详细的配置介绍.不细看先略过到下个步骤. 路由块定义路由树中的节点及其子节点。如果未设置，则其可选配置参数将从其父节点继承。每个警报都在配置的顶级路由处进入路由树，该路由树必须与所有警报匹配（即没有任何配置的匹配器）。然后它遍历子节点。如果continue设置为false，则在第一个匹配的子级之后停止。如果匹配节点上的continue为true，则警报将继续与后续同级节点匹配。如果警报与节点的任何子节点不匹配（没有匹配的子节点，或者不存在），则基于当前节点的配置参数来处理警报。 123456789101112131415161718192021222324252627282930313233[ receiver: &lt;string&gt; ]# 用于将传入警报分组在一起的标签。 # 例如，针对cluster = A和alertname = LatencyHigh的多个警报将被分为一个组。# 要按所有可能的标签进行汇总，请使用特殊值'...'作为唯一的标签名称，例如：group_by：['...']# 这样可以有效地完全禁用聚合，并按原样传递所有警报。 # 除非您的警报量非常低或上游通知系统执行自己的分组，否则这不太可能是您想要的。[ group_by: '[' &lt;labelname&gt;, ... ']' ]# 警报是否应继续匹配后续的同级节点[ continue: &lt;boolean&gt; | default = false ]# 警报必须满足的一组相等匹配器才能匹配节点。match: [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ]# 警报必须满足以匹配节点的一组正则表达式匹配器。match_re: [ &lt;labelname&gt;: &lt;regex&gt;, ... ]# 最初等待为一组警报发送通知的时间。 # 允许等待禁止警报到达或为同一组收集更多初始警报。 （通常〜0秒到几分钟。）[ group_wait: &lt;duration&gt; | default = 30s ]# 发送有关新警报的通知之前要等待的时间，# 该通知将添加到已为其发送了初始通知的一组警报中。 （通常〜5m或更多。）[ group_interval: &lt;duration&gt; | default = 5m ]# 如果已成功发送警报，则等待多长时间才能再次发送通知。 （通常〜3h或更长时间）。[ repeat_interval: &lt;duration&gt; | default = 4h ]# 零个或多个子路由。routes: [ - &lt;route&gt; ... ] &lt;inhibit_rule&gt;当与另一组匹配器匹配的警报（源）存在时，禁止规则静默匹配匹配器集合的警报（目标）。对于相等列表中的标签名称，目标和源警报必须具有相同的标签值。从语义上讲，缺失的标签和空值的标签是一样的。因此，如果源警报和目标警报中均缺少equal中列出的所有标签名称，则将应用抑制规则。为了防止警报抑制自身，与规则的目标端和源端都匹配的警报不能被相同的警报（包括自身）抑制。但是，我们建议选择目标和源匹配器时，警报不会同时匹配双方。这很容易推理，也不会引发这种特殊情况。 1234567891011121314# 必须在警报中完成的匹配项才能被禁用target_match: [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ]target_match_re: [ &lt;labelname&gt;: &lt;regex&gt;, ... ]# 匹配器必须具有一个或多个警报才能使抑制生效source_match: [ &lt;labelname&gt;: &lt;labelvalue&gt;, ... ]source_match_re: [ &lt;labelname&gt;: &lt;regex&gt;, ... ]# 必须在源警报和目标警报中具有相等值的标签才能使抑制生效[ equal: '[' &lt;labelname&gt;, ... ']' ] 12345678910# 接收者的唯一名称name: &lt;string&gt;# 多个通知集成的配置(这里只列出三个其他请看官网)email_configs: [ - &lt;email_config&gt;, ... ]webhook_configs: [ - &lt;webhook_config&gt;, ... ]wechat_configs: [ - &lt;wechat_config&gt;, ... ] &lt;email_config&gt;123456789101112131415161718192021222324252627282930313233343536# 是否通知已解决的警报[ send_resolved: &lt;boolean&gt; | default = false ]# 要向其发送通知的电子邮件地址to: &lt;tmpl_string&gt;# 发件人地址[ from: &lt;tmpl_string&gt; | default = global.smtp_from ]# 发送电子邮件的SMTP主机[ smarthost: &lt;string&gt; | default = global.smtp_smarthost ]# 要标识到SMTP服务器的主机名[ hello: &lt;string&gt; | default = global.smtp_hello ]# SMTP身份验证信息.[ auth_username: &lt;string&gt; | default = global.smtp_auth_username ][ auth_password: &lt;secret&gt; | default = global.smtp_auth_password ][ auth_secret: &lt;secret&gt; | default = global.smtp_auth_secret ][ auth_identity: &lt;string&gt; | default = global.smtp_auth_identity ]# SMTP TLS要求[ require_tls: &lt;bool&gt; | default = global.smtp_require_tls ]# TLS配置tls_config: [ &lt;tls_config&gt; ]# 电子邮件通知的HTML正文[ html: &lt;tmpl_string&gt; | default = '&#123;&#123; template \"email.default.html\" . &#125;&#125;' ]# 电子邮件通知的正文[ text: &lt;tmpl_string&gt; ]# 更多标题电子邮件标题键/值对,重写通知实现以前设置的任何头# 先前由通知实现设置的。[ headers: &#123; &lt;string&gt;: &lt;tmpl_string&gt;, ... &#125; ] &lt;webhook_config&gt;12345678# 是否通知已解决的警报[ send_resolved: &lt;boolean&gt; | default = true ]# 要向其发送HTTP POST请求的终结点url: &lt;string&gt;# http客户端的配置[ http_config: &lt;http_config&gt; | default = global.http_config ] 微信json 格式 123456789101112131415161718192021&#123; \"version\": \"4\", \"groupKey\": &lt;string&gt;, // 识别警报组的密钥（例如重复数据消除） \"status\": \"&lt;resolved|firing&gt;\", \"receiver\": &lt;string&gt;, \"groupLabels\": &lt;object&gt;, \"commonLabels\": &lt;object&gt;, \"commonAnnotations\": &lt;object&gt;, \"externalURL\": &lt;string&gt;, // 指向AlertManager的反向链接 \"alerts\": [ &#123; \"status\": \"&lt;resolved|firing&gt;\", \"labels\": &lt;object&gt;, \"annotations\": &lt;object&gt;, \"startsAt\": \"&lt;rfc3339&gt;\", \"endsAt\": \"&lt;rfc3339&gt;\", \"generatorURL\": &lt;string&gt; // 标识导致警报的实体 &#125;, ... ]&#125; &lt;wechat_config&gt; 123456789101112131415161718# 是否通知已解决的警报[ send_resolved: &lt;boolean&gt; | default = false ]# 与微信API通信时要使用的API密钥[ api_secret: &lt;secret&gt; | default = global.wechat_api_secret ]# 微信api网址[ api_url: &lt;string&gt; | default = global.wechat_api_url ]# 用于身份验证的公司ID[ corp_id: &lt;string&gt; | default = global.wechat_api_corp_id ]# 微信API定义的API请求数据[ message: &lt;tmpl_string&gt; | default = '&#123;&#123; template \"wechat.default.message\" . &#125;&#125;' ][ agent_id: &lt;string&gt; | default = '&#123;&#123; template \"wechat.default.agent_id\" . &#125;&#125;' ][ to_user: &lt;string&gt; | default = '&#123;&#123; template \"wechat.default.to_user\" . &#125;&#125;' ][ to_party: &lt;string&gt; | default = '&#123;&#123; template \"wechat.default.to_party\" . &#125;&#125;' ][ to_tag: &lt;string&gt; | default = '&#123;&#123; template \"wechat.default.to_tag\" . &#125;&#125;' ] 搭建AlertManager服务部署AlertManager可以通过官网https://prometheus.io/download/下载二进制文件.这里演示docker部署AlertManager服务.其他方式请参考官网. docker部署前,需要先完成配置文件的工作. 我在/home/along/下创建了一个配置文件 touch alertmanager.yml之后编辑 vi alertmanager.yml,具体看上文的配置介绍. 启动容器:123docker run -d -p 9093:9093 --name alertmanagter-v /home/along/alertmanager.yml:/etc/alertmanager/alertmanager.ymlquay.io/prometheus/alertmanager 如果加载模板的话需要挂在一下模板目录(模板在下面有介绍):1234docker run -d -p 9093:9093 --name alert9093-v /home/along/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml-v /home/along/alertmanager/template:/alertmanager/templatequay.io/prometheus/alertmanager 服务端口9093,挂在刚才设定的配置文件. 访问IP:9093 可以查看AlertManager的web界面(类似prometheus的web界面). 定义Prometheus警报规则并引入配置配置警报规则文件警报规则文件顾名思义,你想监控的指标何时需要警报.例如设备温度超过多少要警告.创建alert.yml,touch alert.yml12345678910groups:- name: metricsUp # 定义这组告警的组名rules: - alert: 监测对象挂了 # 警报名 可理解为警告的标题 expr: up&#123;instance=\"192.168.23.11:9090\"&#125; == 0 # 判断某值的规则 for: 5m # 上面规则持续5分钟为0进行告警,5分钟内触发是pending状态 labels: # 定义警报标签 severity: waring # 定义警报等级为 waring annotations: # 备注描述 summary: \"设备: &#123;&#123; $labels.instance &#125;&#125; 已断开5分钟\" # 警告中呈现的具体信息可以写在这里 Prometheus引入配置警报规则是Prometheus引入的文件.Prometheus引入文件的方式:12rule_files: - \"/usr/local/prometheus/alert.yml\" # 引入定义的警报规则 测试警报我们上面配置好之后,需要各服务已经读取到相关配置文件了之后开始测试.上面的规则是监测某个监控节点断开,手动断开一个节点.然后5分钟之后观察是否得到警报. 当由警报时收到的邮件为: 访问AlertManager页面也可以看到告警信息: 这里图例有些是演示用,与其他可能不存在关系.(不是同时截图的业务,图片仅供参考) 静默操作演示如果有些警报是我们调试的,例如我这里设置值偏低来演示ping值警报,如果我们测时候不想看到警报,可以通过静默来不让他总是发送警报. 之后点击create 就可以创建此警报的静默操作. 也可以通过正则,警报组名,实例等来静默各种警报. 定义通知模板默认模板我们看到了,他是默认的一个告警模板,在我们测试时候可以使用,如果面向用户使用者似乎这个模板不太友好.而且在面对多数据展示时,此模板也显得不是很清晰. 通过定义了模板,在触发不同警报可以通过AlertManager中,receivers选项来选择模板.12345678templates: - 'template/*.tmpl' # 定义模板中心receivers: - name: 'email' # 警报 email_configs: # 邮箱配置 - to: '******@163.com' # 接收警报的email配置 html: '&#123;&#123; template \"test.html\" . &#125;&#125;' # 设定邮箱的内容模板 headers: &#123; Subject: \"[WARN] 报警邮件\"&#125; # 接收邮件的标题 这段配置中,可以看到警报通过test.html作为模板的.他的位置在上面的定义中可以看到是 template/test.html (如果模板定制有错误,警报可能为空板,不能正常显示内容)现在来配置这个test.html 在 /template/ 下创建 touch test.html模板基于Go的模板系统,详情点击这里如果不想深入连接可以结合默认模板模仿一下语法,默认模板点击这里 1234567891011121314151617181920&#123;&#123; define &quot;email.demo.html&quot; &#125;&#125;&lt;pre&gt;&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot;&gt; &lt;tr&gt; &lt;td&gt;报警名&lt;/td&gt; &lt;td&gt;设备&lt;/td&gt; &lt;td&gt;发现时间&lt;/td&gt; &lt;td&gt;详情&lt;/td&gt; &lt;/tr&gt; &#123;&#123; range $i, $alert := .Alerts &#125;&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123; index $alert.Labels &quot;alertname&quot; &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; $alert.Labels.instance &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; $alert.StartsAt.Format &quot;2006-01-02 15:04:05&quot; &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; $alert.Annotations.summary &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;&#123; end &#125;&#125;&lt;/table&gt;&lt;/pre&gt;&#123;&#123; end &#125;&#125; 模板保存后,测试邮件接收情况: 模板时区问题Prometheus中所有时间都是UTC时间,为了便于我们展示友好时间(东八区),我们需要计算一下时间.修改模板时间:1&lt;td&gt;&#123;&#123; ($alert.StartsAt.Add 28800e9).Format \"2006-01-02 15:04:05\" &#125;&#125;&lt;/td&gt;","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/tags/Prometheus/"},{"name":"AlertManager","slug":"AlertManager","permalink":"http://blog.51ai.vip/tags/AlertManager/"}]},{"title":"windows10家庭版启用组策略gpedit.msc","slug":"windows10家庭版启用组策略gpedit-msc","date":"2019-10-15T03:35:11.000Z","updated":"2019-10-15T03:43:21.878Z","comments":true,"path":"2019/10/15/windows10家庭版启用组策略gpedit-msc/","link":"","permalink":"http://blog.51ai.vip/2019/10/15/windows10家庭版启用组策略gpedit-msc/","excerpt":"","text":"启用组策略gpedit.msc家庭版很多功能不能使用,凑巧用的就是家庭版. 还想使用gpedit.msc来关闭windows10的更新.找到一个可行的方法. 需要创建一个脚本. 如果你没有编辑器,那么可以创建一个文本文档. 复制下面一段到本文中. 123456@echo offpushd \"%~dp0\"dir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientExtensions-Package~3*.mum &gt;List.txtdir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientTools-Package~3*.mum &gt;&gt;List.txtfor /f %%i in ('findstr /i . List.txt 2^&gt;nul') do dism /online /norestart /add-package:\"C:\\Windows\\servicing\\Packages\\%%i\"pause 如果编辑器直接复制一个文档另存到XX.cmd 即可. 如果是文本文档那么就是把后缀的.txt改成.cmd. 管理员身份运行这个脚本.等他走完会退出,win+r 即可使用gpedit.msc了. 美滋滋!~ 禁用windows10更新 win+r 输入gpedit.msc. “本地计算机策略”-“计算机配置”-“管理模板”-“Windows组件”-“Windows 更新”-“配置自动更新”. 点击配置自动更新设置为禁用","categories":[{"name":"windows","slug":"windows","permalink":"http://blog.51ai.vip/categories/windows/"}],"tags":[{"name":"windows","slug":"windows","permalink":"http://blog.51ai.vip/tags/windows/"}]},{"title":"prometueus.yml配置文件说明","slug":"prometueus-yml配置文件说明","date":"2019-10-09T07:20:58.000Z","updated":"2019-10-12T05:29:29.893Z","comments":true,"path":"2019/10/09/prometueus-yml配置文件说明/","link":"","permalink":"http://blog.51ai.vip/2019/10/09/prometueus-yml配置文件说明/","excerpt":"","text":"整体配置prometueus.yml 配置文件注解与说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849global: # 全局配置 scrape_interval: 15s # 默认值为 15s，用于设置每次数据收集的间隔 scrape_timeout: 10s # 默认10s,收集超时时间 evaluation_interval: 15s # 记录规则/告警的执行周期 默认1m external_labels: # 所有时间序列和警告与外部通信时用的外部标签 monitor: 'ctmonitor'rule_files: # 指定告警规则文件&amp;记录文件 - \"/usr/local/prometheus/rules.yml\"alerting: # 告警管理配置 alert_relable_configs: # 修改告警内容 - alertmanagers: # 告警管理起配置 - static_configs: # 静态配置 - targets: # 警告器地址 - 172.16.23.12:9093# 用于配置 scrape 的 endpoint 配置需要 scrape 的 targets 以及相应的参数# 抓取(pull)，即监控目标配置。默认只有主机本身的监控配置 scrape_configs: # 抓取- job_name: prometheus # 默认情况下分配给刮削度量的作业名称。 scrape_interval: 5s # 从这项工作中获取目标的频率。 scrape_timeout: 3s # 每次获取超时时间 honor_timestamps: true # 默认false, 在获取时是否使用当前的时间戳 metrics_path: /metrics # 从目标获取度量的http资源路径。 scheme: http # static_configs: # 为此作业标记的静态配置目标的列表。 - targets: # 目监控标 - 172.16.23.12:9090 # 设备地址+端口- job_name: 'snmp-10.0.0.1' scrape_interval: 30s scrape_timeout: 20s static_configs: - targets: - 10.0.0.1 # SNMP设备,端口默认5060 metrics_path: /snmp params: module: [if_mib] relabel_configs: # 重定义标签 - source_labels: [__address__] # 需要修改的标签 target_label: __param_target # 改成的标签 - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 172.16.23.12:9117 各部分详解scrape_configs监控配置 &lt;scrape_configs&gt;配置采集目标1、根据配置的任务（job）以http/s周期性的收刮（scrape/pull）2、指定目标（target）上的指标（metric）。目标（target）3、可以以静态方式或者自动发现方式指定。Prometheus将收刮（scrape）的指标（metric）保存在本地或者远程存储上。 &lt;scrape_config&gt;部分指定一组描述如何刮除它们的目标和参数。 在一般情况下，一个scrape配置指定单个作业。 在高级配置中，这可能会改变。目标可以通过&lt;static_configs&gt;参数静态配置，也可以使用其中一种支持的服务发现机制动态发现。此外，&lt;relabel_configs&gt;允许在抓取之前对任何目标及其标签进行高级修改。其中&lt;job_name&gt;在所有scrape配置中必须是唯一的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111# 默认分配给已抓取指标的job名称。job_name: &lt;job_name&gt;# 从job中抓取目标的频率.[ scrape_interval: &lt;duration&gt; | default = &lt;global_config.scrape_interval&gt; ]# 抓取此job时，每次抓取超时时间.[ scrape_timeout: &lt;duration&gt; | default = &lt;global_config.scrape_timeout&gt; ]# 从目标获取指标的HTTP资源路径.[ metrics_path: &lt;path&gt; | default = /metrics ]# honor_labels控制Prometheus如何处理已经存在于已抓取数据中的标签与Prometheus将附加服务器端的标签之间的冲突（\"job\"和\"instance\"标签，手动配置的目标标签以及服务发现实现生成的标签）。# # 如果honor_labels设置为\"true\"，则通过保留已抓取数据的标签值并忽略冲突的服务器端标签来解决标签冲突。## 如果honor_labels设置为\"false\"，则通过将已抓取数据中的冲突标签重命名为\"exported_ &lt;original-label&gt;\"（例如\"exported_instance\"，\"exported_job\"）然后附加服务器端标签来解决标签冲突。 这对于联合等用例很有用，其中应保留目标中指定的所有标签。# # 请注意，任何全局配置的\"external_labels\"都不受此设置的影响。 在与外部系统通信时，它们始终仅在时间序列尚未具有给定标签时应用，否则将被忽略。# [ honor_labels: &lt;boolean&gt; | default = false ]# 配置用于请求的协议方案.[ scheme: &lt;scheme&gt; | default = http ]# 可选的HTTP URL参数.params: [ &lt;string&gt;: [&lt;string&gt;, ...] ]# 使用配置的用户名和密码在每个scrape请求上设置`Authorization`标头。 password和password_file是互斥的。basic_auth: [ username: &lt;string&gt; ] [ password: &lt;secret&gt; ] [ password_file: &lt;string&gt; ]# 使用配置的承载令牌在每个scrape请求上设置`Authorization`标头。 它`bearer_token_file`和是互斥的。[ bearer_token: &lt;secret&gt; ]# 使用配置的承载令牌在每个scrape请求上设置`Authorization`标头。 它`bearer_token`和是互斥的。[ bearer_token_file: /path/to/bearer/token/file ]# 配置scrape请求的TLS设置.tls_config: [ &lt;tls_config&gt; ]# 可选的代理URL.[ proxy_url: &lt;string&gt; ]# Azure服务发现配置列表.azure_sd_configs: [ - &lt;azure_sd_config&gt; ... ]# Consul服务发现配置列表.consul_sd_configs: [ - &lt;consul_sd_config&gt; ... ]# DNS服务发现配置列表。dns_sd_configs: [ - &lt;dns_sd_config&gt; ... ]# EC2服务发现配置列表。ec2_sd_configs: [ - &lt;ec2_sd_config&gt; ... ]# OpenStack服务发现配置列表。openstack_sd_configs: [ - &lt;openstack_sd_config&gt; ... ]# 文件服务发现配置列表。file_sd_configs: [ - &lt;file_sd_config&gt; ... ]# GCE服务发现配置列表。gce_sd_configs: [ - &lt;gce_sd_config&gt; ... ]# Kubernetes服务发现配置列表。kubernetes_sd_configs: [ - &lt;kubernetes_sd_config&gt; ... ]# Marathon服务发现配置列表。marathon_sd_configs: [ - &lt;marathon_sd_config&gt; ... ]# AirBnB的神经服务发现配置列表。nerve_sd_configs: [ - &lt;nerve_sd_config&gt; ... ]# Zookeeper Serverset服务发现配置列表。serverset_sd_configs: [ - &lt;serverset_sd_config&gt; ... ]# Triton服务发现配置列表。triton_sd_configs: [ - &lt;triton_sd_config&gt; ... ]# 此job的标记静态配置目标列表。static_configs: [ - &lt;static_config&gt; ... ]# 目标重新标记配置列表。relabel_configs: [ - &lt;relabel_config&gt; ... ]# 度量标准重新配置列表。metric_relabel_configs: [ - &lt;relabel_config&gt; ... ]# 对每个将被接受的样本数量的每次抓取限制。# 如果在度量重新标记后存在超过此数量的样本，则整个抓取将被视为失败。 0表示没有限制。[ sample_limit: &lt;int&gt; | default = 0 ] rule_files记录规则,编写的记录规则是定义一些常用计算规则.这些规则会存储到数据中. 12rule_files: [ - &lt;filepath_glob&gt; ... ] alertingAlertmanager相关配置 12345alerting: alert_relabel_configs: [ - &lt;relabel_config&gt; ... ] alertmanagers: [ - &lt;alertmanager_config&gt; ... ] &lt;alertmanager_config&gt;alertmanager_config部分指定Prometheus服务器向其发送警报的Alertmanager实例。 它还提供参数以配置如何与这些Alertmanagers进行通信。Alertmanagers可以通过static_configs参数静态配置，也可以使用其中一种支持的服务发现机制动态发现。此外，relabel_configs允许从发现的实体中选择Alertmanagers，并对使用的API路径提供高级修改，该路径通过alerts_path标签公开。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# 推送警报时按目标Alertmanager超时。[ timeout: &lt;duration&gt; | default = 10s ]# 将推送HTTP路径警报的前缀。[ path_prefix: &lt;path&gt; | default = / ]# 配置用于请求的协议方案。[ scheme: &lt;scheme&gt; | default = http ]# 使用配置的用户名和密码在每个请求上设置`Authorization`标头。 password和password_file是互斥的。basic_auth: [ username: &lt;string&gt; ] [ password: &lt;string&gt; ] [ password_file: &lt;string&gt; ]# 使用配置的承载令牌在每个请求上设置“Authorization”标头。 它与`bearer_token_file`互斥。[ bearer_token: &lt;string&gt; ]# 使用配置的承载令牌在每个请求上设置“Authorization”标头。 它与`bearer_token`互斥。[ bearer_token_file: /path/to/bearer/token/file ]# 配置scrape请求的TLS设置。tls_config: [ &lt;tls_config&gt; ]# 可选的代理URL。[ proxy_url: &lt;string&gt; ]# Azure服务发现配置列表。azure_sd_configs: [ - &lt;azure_sd_config&gt; ... ]# Consul服务发现配置列表。consul_sd_configs: [ - &lt;consul_sd_config&gt; ... ]# DNS服务发现配置列表。dns_sd_configs: [ - &lt;dns_sd_config&gt; ... ]# ECS服务发现配置列表。ec2_sd_configs: [ - &lt;ec2_sd_config&gt; ... ]# 文件服务发现配置列表。file_sd_configs: [ - &lt;file_sd_config&gt; ... ]# GCE服务发现配置列表。gce_sd_configs: [ - &lt;gce_sd_config&gt; ... ]# K8S服务发现配置列表。kubernetes_sd_configs: [ - &lt;kubernetes_sd_config&gt; ... ]# Marathon服务发现配置列表。marathon_sd_configs: [ - &lt;marathon_sd_config&gt; ... ]# AirBnB's Nerve 服务发现配置列表。nerve_sd_configs: [ - &lt;nerve_sd_config&gt; ... ]# Zookepper服务发现配置列表。serverset_sd_configs: [ - &lt;serverset_sd_config&gt; ... ]# Triton服务发现配置列表。triton_sd_configs: [ - &lt;triton_sd_config&gt; ... ]# 标记为静态配置的Alertmanagers列表。static_configs: [ - &lt;static_config&gt; ... ]# Alertmanager重新配置列表。relabel_configs: [ - &lt;relabel_config&gt; ... ] remote_write云端写入数据 &lt;remote_write&gt;write_relabel_configs是在将样本发送到远程端点之前应用于样本的重新标记。 在外部标签之后应用写入重新标记。 这可用于限制发送的样本。 有一个如何使用此功能的小型演示。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 要发送样本的端点的URL.url: &lt;string&gt;# 对远程写端点的请求超时。[ remote_timeout: &lt;duration&gt; | default = 30s ]# 远程写入重新标记配置列表。write_relabel_configs: [ - &lt;relabel_config&gt; ... ]# 使用配置的用户名和密码在每个远程写请求上设置`Authorization`标头.password和password_file是互斥的。basic_auth: [ username: &lt;string&gt; ] [ password: &lt;string&gt; ] [ password_file: &lt;string&gt; ]# 使用配置的承载令牌在每个远程写请求上设置`Authorization`头。 它与`bearer_token_file`互斥。[ bearer_token: &lt;string&gt; ]# 使用配置的承载令牌在每个远程写请求上设置`Authorization`头。 它与`bearer_token`互斥。[ bearer_token_file: /path/to/bearer/token/file ]# 配置远程写入请求的TLS设置。tls_config: [ &lt;tls_config&gt; ]# 可选的代理URL。[ proxy_url: &lt;string&gt; ]# 配置用于写入远程存储的队列。queue_config: # 在我们开始删除之前每个分片缓冲的样本数。 [ capacity: &lt;int&gt; | default = 10000 ] # 最大分片数，即并发数。 [ max_shards: &lt;int&gt; | default = 1000 ] # 最小分片数，即并发数。 [ min_shards: &lt;int&gt; | default = 1 ] # 每次发送的最大样本数。 [ max_samples_per_send: &lt;int&gt; | default = 100] # 样本在缓冲区中等待的最长时间。 [ batch_send_deadline: &lt;duration&gt; | default = 5s ] # 在可恢复错误上重试批处理的最大次数。 [ max_retries: &lt;int&gt; | default = 3 ] # 初始重试延迟。 每次重试都会加倍。 [ min_backoff: &lt;duration&gt; | default = 30ms ] # 最大重试延迟。 [ max_backoff: &lt;duration&gt; | default = 100ms ] remote_read云端读取数据 &lt;remote_read&gt;12345678910111213141516171819202122232425262728293031# 要发送样本的端点的URL.url: &lt;string&gt;# 可选的匹配器列表，必须存在于选择器中以查询远程读取端点。required_matchers: [ &lt;labelname&gt;: &lt;labelvalue&gt; ... ]# 对远程读取端点的请求超时。[ remote_timeout: &lt;duration&gt; | default = 1m ]# 本地存储应该有完整的数据。[ read_recent: &lt;boolean&gt; | default = false ]# 使用配置的用户名和密码在每个远程写请求上设置`Authorization`标头.password和password_file是互斥的。basic_auth: [ username: &lt;string&gt; ] [ password: &lt;string&gt; ] [ password_file: &lt;string&gt; ]# 使用配置的承载令牌在每个远程写请求上设置`Authorization`头。 它与`bearer_toke_filen`互斥。[ bearer_token: &lt;string&gt; ]# 使用配置的承载令牌在每个远程写请求上设置`Authorization`头。 它与`bearer_token`互斥。[ bearer_token_file: /path/to/bearer/token/file ]# 配置远程写入请求的TLS设置。tls_config: [ &lt;tls_config&gt; ]# 可选的代理URL。[ proxy_url: &lt;string&gt; ] relabel_configs用来重新打标记,修改标签. &lt;relabel_configs&gt;Prometheus 重新标签允许在采集之前对任何目标及其标签进行修改 • 重命名标签名 • 删除标签 • 过滤目标 action：重新标签动作 replace：默认，通过regex匹配source_label的值，使用replacement来引用表达式匹配的分组 keep：删除regex与连接不匹配的目标 source_labels drop：删除regex与连接匹配的目标 source_labels labeldrop：删除regex匹配的标签 labelkeep：删除regex不匹配的标签 hashmod：设置target_label为modulus连接的哈希值source_labels labelmap：匹配regex所有标签名称。然后复制匹配标签的值进行分组，replacement分组引用（${1},${2},…）替代 12345678910111213141516171819202122relable_configs:# 源标签从现有标签中选择值。 它们的内容使用已配置的分隔符进行连接，并与已配置的正则表达式进行匹配，以进行替换，保留和删除操作。[ source_labels: '[' &lt;labelname&gt; [, ...] ']' ]# 分隔符放置在连接的源标签值之间。[ separator: &lt;string&gt; | default = ; ]# 在替换操作中将结果值写入的标签。# 替换操作是强制性的。 正则表达式捕获组可用。[ target_label: &lt;labelname&gt; ]# 与提取的值匹配的正则表达式。[ regex: &lt;regex&gt; | default = (.*) ]# 采用源标签值的散列的模数。[ modulus: &lt;uint64&gt; ]# 如果正则表达式匹配，则执行正则表达式替换的替换值。 正则表达式捕获组可用。[ replacement: &lt;string&gt; | default = $1 ]# 基于正则表达式匹配执行的操作。[ action: &lt;relabel_action&gt; | default = replace ]","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/tags/Prometheus/"}]},{"title":"curl: (3) Illegal characters found in URL","slug":"curl-3-Illegal-characters-found-in-URL","date":"2019-10-09T06:45:13.000Z","updated":"2019-10-09T06:56:42.624Z","comments":true,"path":"2019/10/09/curl-3-Illegal-characters-found-in-URL/","link":"","permalink":"http://blog.51ai.vip/2019/10/09/curl-3-Illegal-characters-found-in-URL/","excerpt":"","text":"curl: (3) Illegal characters found in URL昨天在服务器上执行一个脚本,在linux新建的sh,把本地编辑器的内容粘贴到文件里.结果执行的时候报错了. 问题就是 curl:(3)Illegal characters found in URL 看着一脸懵逼啊!~ google了一下,看到几个方法.其中一个我感觉还不错: 首先vi 进入sh脚本 vi XXX.sh :set ff? # 这里我现实的是 fileforma=dos 我这里显示是这个 :set fileformat=unix # 把fileforma 设置好 :wq 通过这个方式,可以解决这个问题,网上也有人提出其他方法把\\r\\n 手动替换\\n的. 参考:http://www.itbiancheng.com/linux/4885.html","categories":[{"name":"note","slug":"note","permalink":"http://blog.51ai.vip/categories/note/"}],"tags":[{"name":"curl","slug":"curl","permalink":"http://blog.51ai.vip/tags/curl/"}]},{"title":"yaml规则","slug":"yaml规则","date":"2019-09-24T02:20:31.000Z","updated":"2019-09-24T02:34:14.278Z","comments":true,"path":"2019/09/24/yaml规则/","link":"","permalink":"http://blog.51ai.vip/2019/09/24/yaml规则/","excerpt":"","text":"yml 语法最近经常配置一些服务，发现大部分都是yml类型文件。小记一下。 规则 大小写敏感 缩进表示层级 注释 # 结构：对象： ：符号 1name: admin 数组： - 符号 1234user: - name: admin - height: 178 - age: 30 字符串： 默认无引号，内部含有空格或特殊符号需要加’’ 12name: admindesc: 'he was cool' null： ~ 1value: ~ 层级依靠缩进： 12345job: - jobconfig: name: 'snmp-sw01' - target: - 192.168.1.88","categories":[{"name":"yaml","slug":"yaml","permalink":"http://blog.51ai.vip/categories/yaml/"}],"tags":[{"name":"yaml","slug":"yaml","permalink":"http://blog.51ai.vip/tags/yaml/"}]},{"title":"Grafana中文化","slug":"Grafana汉化","date":"2019-09-16T07:37:46.000Z","updated":"2019-09-19T08:18:00.378Z","comments":true,"path":"2019/09/16/Grafana汉化/","link":"","permalink":"http://blog.51ai.vip/2019/09/16/Grafana汉化/","excerpt":"","text":"可视化图表Grafana是一个通用的可视化工具。通过Grafana可以管理用户权限，数据分析，查看，导出，设置告警等。 仪表盘Dashboard通过数据源定义好可视化的数据来源之后，对于用户而言最重要的事情就是实现数据的可视化。 面板 PanelPanel是Grafana中最基本的可视化单元。每一种类型的面板都提供了相应的查询编辑器(Query Editor)，让用户可以从不同的数据源（如Prometheus）中查询出相应的监控数据，并且以可视化的方式展现。Grafana中所有的面板均以插件的形式进行使用，当前内置了5种类型的面板，分别是：Graph，Singlestat，Heatmap, Dashlist，Table以及Text。 翻译工作上面简单介绍了一下工具，主要是让我们方便查看监控的数据。这里我还是没有更深入的去研究公式等图形的设置。这里先主要写一下翻译方面的工作。 公司也考虑展示内容为中文化比较好，这里Grafana没有提供语言包的方式来处理多语言问题。在我查看代码过程中，发现工具后台是在GO里面写死的很多导航，返回值等数据。前台是在页面上直接写的很多内容。所以我个人认为无法使用语言包来直接处理多语言问题。那就只好自己来搞定了。 翻译的内容更具代码查看，主要分为两大部分： 后端： go文件，主要内容在/pkg 目录下。 前端： 1. 系统页面 2. 插件页面 这些在/public 目录下 准备工作首先git clone Grafana库git clone https://github.com/chenweil/grafana.git 之后我们根据自己翻译的版本来检出自己的项目。这里我们使用的v6.3.4 ，官方版本中可以查看到tag v6.3.4,并重命名自己的分支为6.3.4-chs：git checkout -b 6.3.4-chs 通过 git branch 命令查看自己处于哪个分支上。这里如果你不是很熟悉git命令行，可以使用sourcetree工具操作，相对来说点点鼠标就可以搞定了。 我们在自己创建的分支就可以来处理我们的工作了。 前端调试环境需要 npm，nodejs，yarn开启调试环境时候，是开启前端的热加载来协助我们调试。这里安装完三个环境可能在执行 yarn start 时报错，这里如果你是在windows上，需要再安装一下sass.(根据报错来看问题，我这里遇到缺少sass问题) 当我们yarn start 执行后，等待一段时间，build at 时间证明准备工作已完成，下面就需要我们在调试模式下测试了。 还需要一个调试的Grafana服务程序，这里是windows环境，所以直接从官方下载了zip包，执行bin下的grafana-server.exe 来启动服务。需要再conf文件夹修改一下public前端资源的配置，如果不修改那么你翻译的信息是看不到的，服务会直接读取的当前的public，我们这需要读取翻译的public文件位置。 配置在windows服务程序的 /conf/defaults.ini修改内容：12app_mode = development # 开发模式static_root_path = D:\\grafana\\public #这里配置到git拉取得位置的public 按照正常的操作 是需要开启webpack-dev-server 访问端口是3333我这里没有这么设置，直接利用3000端口调试的。（当我们yarn start 后，通过修改页面可以看修改的内容。） 翻译前端文件前面环境已经搭建好之后，我们通过修改页面文件展示内容来翻译。例如翻译登陆页面：/public/app/partials/login.html把对应的英文改为中文，保存后webpack会处理。处理完成刷新页面可以看到结果。 前端翻译文件不止html，还有ts，tsx等文件。这里如果不知道具体文件可以在public文件夹下，通过全局搜索页面的单词等信息定位到文件。我没有翻译带有test 的测试文件。 最后我们把需要的文件都翻译之后，通过yarn build 生成文件。这些文件都存在生成的目录/public/build中。把这些文件覆盖到自己搭建的项目中完成汉文。建议把整体public目录替换。重启服务既可以看到中文版的页面了。 后端环境后端是用GO写的。后端我没有调试，不想前端那样可以边调边看。我的办法就是全部改完，build程序，启动查看后端翻译的结果。所需，本人是在windows10下处理的，需要gcc，go。 翻译后端文件文件所在位置： /pkg/ 首页我们的导航，二级菜单这些不是前端控制的，这些是在 /pkg/api/index.go 其余还有很多文件，内容包含：html数据，返回值信息，debug信息等。如果你前端翻译完成，那么后端对你来说也是很轻松的。 请注意一些参数或者判断不要给翻译了 当翻译完成后，需要build。首先到项目根目录，这里可以看到 build.go 文件。用这个来生成后端程序。 windows下可以build .exe程序。 时间很短，便于我们调试。 build前，先steup一下，执行 go run build.go setup。 12345$ go run build.go setupVersion: 6.3.4, Linux Version: 6.3.4, Package Iteration: 1568870230go install -v ./pkg/cmd/grafana-servergithub.com/grafana/grafana/pkg/apigithub.com/grafana/grafana/pkg/cmd/grafana-server 如果没有报错，那么证明是可以执行build了。这里可能你会遇到一些错误，出现错误先解决错误再重新执行 go run build.go setup，直到没有错误。我遇到一下错误： error loading module requirements这个问题一查一大把，原因就是你需要的模块下载不到，地址被墙。解决方式： 其中一种：go.mod 添加replace() 替换地址。下面并非全部用到，我是偷懒全粘上。 replace ( golang.org/x/build =&gt; github.com/golang/build v0.0.0-20190416225751-b5f252a0a7dd golang.org/x/crypto =&gt; github.com/golang/crypto v0.0.0-20190411191339-88737f569e3a golang.org/x/exp =&gt; github.com/golang/exp v0.0.0-20190413192849-7f338f571082 golang.org/x/image =&gt; github.com/golang/image v0.0.0-20190417020941-4e30a6eb7d9a golang.org/x/lint =&gt; github.com/golang/lint v0.0.0-20190409202823-959b441ac422 golang.org/x/mobile =&gt; github.com/golang/mobile v0.0.0-20190415191353-3e0bab5405d6 golang.org/x/net =&gt; github.com/golang/net v0.0.0-20190415214537-1da14a5a36f2 golang.org/x/oauth2 =&gt; github.com/golang/oauth2 v0.0.0-20190402181905-9f3314589c9a golang.org/x/perf =&gt; github.com/golang/perf v0.0.0-20190312170614-0655857e383f golang.org/x/sync =&gt; github.com/golang/sync v0.0.0-20190412183630-56d357773e84 golang.org/x/sys =&gt; github.com/golang/sys v0.0.0-20190416152802-12500544f89f golang.org/x/text =&gt; github.com/golang/text v0.3.0 golang.org/x/time =&gt; github.com/golang/time v0.0.0-20190308202827-9d24e82272b4 golang.org/x/tools =&gt; github.com/golang/tools v0.0.0-20190417005754-4ca4b55e2050 golang.org/x/xerrors =&gt; github.com/golang/xerrors v0.0.0-20190410155217-1f06c39b4373 google.golang.org/api =&gt; github.com/googleapis/google-api-go-client v0.3.2 google.golang.org/appengine =&gt; github.com/golang/appengine v1.5.0 google.golang.org/genproto =&gt; github.com/google/go-genproto v0.0.0-20190415143225-d1146b9035b9 google.golang.org/grpc =&gt; github.com/grpc/grpc-go v1.20.0 gopkg.in/asn1-ber.v1 =&gt; github.com/go-asn1-ber/asn1-ber v0.0.0-20181015200546-f715ec2f112d gopkg.in/fsnotify.v1 =&gt; github.com/Jwsonic/recinotify v0.0.0-20151201212458-7389700f1b43 gopkg.in/gorethink/gorethink.v4 =&gt; github.com/rethinkdb/rethinkdb-go v4.0.0+incompatible gopkg.in/ini.v1 =&gt; github.com/go-ini/ini v1.42.0 gopkg.in/src-d/go-billy.v4 =&gt; github.com/src-d/go-billy v4.2.0+incompatible gopkg.in/src-d/go-git-fixtures.v3 =&gt; github.com/src-d/go-git-fixtures v3.4.0+incompatible gopkg.in/yaml.v2 =&gt; github.com/go-yaml/yaml v2.1.0+incompatible k8s.io/api =&gt; github.com/kubernetes/api v0.0.0-20190416052506-9eb4726e83e4 k8s.io/apimachinery =&gt; github.com/kubernetes/apimachinery v0.0.0-20190416092415-3370b4aef5d6 k8s.io/client-go =&gt; github.com/kubernetes/client-go v11.0.0+incompatible k8s.io/klog =&gt; github.com/simonpasquier/klog-gokit v0.1.0 k8s.io/kube-openapi =&gt; github.com/kubernetes/kube-openapi v0.0.0-20190401085232-94e1e7b7574c k8s.io/utils =&gt; github.com/kubernetes/utils v0.0.0-20190308190857-21c4ce38f2a7 sigs.k8s.io/yaml =&gt; github.com/kubernetes-sigs/yaml v1.1.0 go.uber.org/atomic =&gt; github.com/uber-go/atomic v1.3.2 ) 还有方法是通过设置Module GOPROXY代理。大概意思就是当构建或运行你的应用时,Go 会通过 GOPROXY 获取依赖。 这个我没测试，有兴趣自行查阅。 exec: “gcc”: executable file not found in %PATH% 这个问题是我们环境没有gcc，这个玩意儿需要下载一个软件MinGW。 此地址提供的压缩包文件。解压可以使用，此网站也提供下载器安装方式。这网站下载贼慢 解压之后设置环境变量，当前解压完路径是： C:\\MinGW\\mingw64 在环境变量添加此目录。 cmd 测试 gcc -v 有信息即ok。 没有问题 执行 go run build.go build完成后，就可以得到bin文件，位置在 /bin/windows-amd64/ ， 里面有grafana-server.exe 程序。 在测试前端时候，用的那个windwos程序可以下岗了，把build之后的bin程序+md5文件一起复制到这目录里。如果你不放心提前先备份一份。 之后按照测试前端那样，打开服务，访问3000，查看自己汉化后端的成果吧。 生成docker镜像docker build -t grafana/grafana:dev . 还没完，我们刚才只是测试一下自己汉化的后端是否可以。如果测试完都可以之后，我们还是要把它build成镜像，利用docker来运行服务。如果你不想用docker，就考虑在build为linux程序。 生成docker镜像可以分为两种，一种是你所在linux/amd64中生成的镜像，另一种是通用的镜像。考虑第二种通用镜像：make build-docker-full 或者 docker build -t grafana/grafana:dev . 最后我发现这些可以拿到我的测试环境去完成。那么我就打包移到测试环境去生成镜像，镜像做好 加载汉化的public 就可以了。 到此终于结束啦。","categories":[{"name":"可视化图表","slug":"可视化图表","permalink":"http://blog.51ai.vip/categories/可视化图表/"}],"tags":[{"name":"Grafana","slug":"Grafana","permalink":"http://blog.51ai.vip/tags/Grafana/"}]},{"title":"Centos7安装nodejs","slug":"Centos7安装nodejs","date":"2019-09-02T02:15:01.000Z","updated":"2019-09-02T02:22:36.486Z","comments":true,"path":"2019/09/02/Centos7安装nodejs/","link":"","permalink":"http://blog.51ai.vip/2019/09/02/Centos7安装nodejs/","excerpt":"","text":"安装nodejs下载官方node的tar包:https://nodejs.org/en/download/ wget https://nodejs.org/dist/v10.16.3/node-v10.16.3-linux-x64.tar.xz 解压下载文件tar -xvf node-v10.16.3-linux-x64.tar.xz 部署bin这里下载位置为家里面 ~/ ln -s ~/node-v10.16.3-linux-x64/bin/node /usr/bin/node ln -s ~/node-v10.16.3-linux-x64/bin/npm /usr/bin/npm 一个是node 另一个是npm 验证node -vnpm -v","categories":[{"name":"Centos","slug":"Centos","permalink":"http://blog.51ai.vip/categories/Centos/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://blog.51ai.vip/tags/nodejs/"}]},{"title":"Prometheus-snmp_export部署","slug":"Prometheus-snmp-export部署","date":"2019-08-29T02:06:01.000Z","updated":"2019-08-29T06:00:42.770Z","comments":true,"path":"2019/08/29/Prometheus-snmp-export部署/","link":"","permalink":"http://blog.51ai.vip/2019/08/29/Prometheus-snmp-export部署/","excerpt":"","text":"SNMPSNMP(simple network management protocol)是因特网架构委员会IAB定义的一个应用层协议。SNMP广泛用于管理和监控网络设备，大多数专业的网络设备都有SNMP agent代理，这些代理被激活和配置后用于和SNMP管理 NMS(network management system)网络管理系统通信。 目的通过snmp_export,获取设备信息. 准备系统: centos7,docker19.之前已经安装好 Prometheus 此处目标设备是华为交换机 s2700 部署snmp_expoersnmp.yml 配置文件不是自己定义的,是通过注册生成或下载的.这里我通过github下载配置文件. snmp.yml 配置snmp_export 配置文件 snmp.yml 1234567891011121314version: 2auth: community: **交换机设置的团体名**``` 查找到if_mib 再此段结尾中加入 上面的配置(大概行数6199).![demo](https://t1.picb.cc/uploads/2019/08/29/gjuSAc.png)### 部署snmp_expor```bashdocker run -d --restart always \\-v /home/along/snmp.yml:/etc/snmp_exporter/snmp.yml \\-p 9116:9116 --name snmp-exporter prom/snmp-exporter \\ --config.file=\"/etc/snmp_exporter/snmp.yml\" 配置华为s2700交换机自行查阅文档.懒得写了. 验证服务访问 http://IP:9116/metrics 能返回数据,snmp_export服务正常. 测试是否能获取到目标设备的数据:访问 http://IP:9116/snmp?target=DEVIP能获取到数据,配置成功. 注意防火墙 把需要的端口加入规则中,不然访问不到排查绕弯路 配置promthues修改 promthues.yml文件. 添加一个新的job.1234567891011121314151617181920212223242526272829303132- job_name: snmp honor_timestamps: true params: module: - if_mib scrape_interval: 15s scrape_timeout: 10s metrics_path: /snmp scheme: http static_configs: - targets: - 172.16.23.253 labels: tag: huawei-switch-s2700 relabel_configs: - source_labels: [__address__] separator: ; regex: (.*) target_label: __param_target replacement: $1 action: replace - source_labels: [__param_target] separator: ; regex: (.*) target_label: instance replacement: $1 action: replace - separator: ; regex: (.*) target_label: __address__ replacement: 172.16.23.12:9116 action: replace 之前部署prometheus 有一个参数是为了热加载配置的.这里需要reload一下配置,curl -X POST http://IP:9090/-/reload,如果你没有就重启服务吧. 验证 Prometheus配置访问 http://IP:9090/点击 Status-&gt;Target 可以看到监控的节点,之前我们是有一个,现在是两个节点了. 有数据之后,就可以在grafana中展示设备的数据了. 参考https://github.com/prometheus/snmp_exporter https://prometheus.io/docs/instrumenting/exporters/ http://owelinux.github.io/owelinux.github.io/2018/07/25/article8-linux-prometheus/","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"}],"tags":[{"name":"SNMP","slug":"SNMP","permalink":"http://blog.51ai.vip/tags/SNMP/"}]},{"title":"Prometheus+Grafana安装搭建","slug":"Prometheus-Grafana安装搭建","date":"2019-08-28T08:23:05.000Z","updated":"2019-10-09T05:34:06.823Z","comments":true,"path":"2019/08/28/Prometheus-Grafana安装搭建/","link":"","permalink":"http://blog.51ai.vip/2019/08/28/Prometheus-Grafana安装搭建/","excerpt":"","text":"介绍 Prometheus是由SoundCloud开发的开源监控报警系统和时序列数据库(TSDB)。Prometheus使用Go语言开发，是Google BorgMon监控系统的开源版本。 2016年由Google发起Linux基金会旗下的原生云基金会(Cloud Native Computing Foundation), 将Prometheus纳入其下第二大开源项目。Prometheus目前在开源社区相当活跃。 Prometheus和Heapster(Heapster是K8S的一个子项目，用于获取集群的性能数据。)相比功能更完善、更全面。Prometheus性能也足够支撑上万台规模的集群。 Prometheus的特点: 多维度数据模型。 灵活的查询语言。 不依赖分布式存储，单个服务器节点是自主的。 通过基于HTTP的pull方式采集时序数据。 可以通过中间网关进行时序列数据推送。 通过服务发现或者静态配置来发现目标服务对象。 支持多种多样的图表和界面展示，比如Grafana等。 架构图 Prometheus服务大致过程： Prometheus 定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。Prometheus支持通过配置文件、文本文件、Zookeeper、Consul、DNS SRV Lookup等方式指定抓取目标。Prometheus采用PULL的方式进行监控，即服务器可以直接通过目标PULL数据或者间接地通过中间网关来Push数据。 Prometheus在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。 Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。 PushGateway支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。 Alertmanager是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。 Prometheus 支持通过SNMP协议获取mertics数据.通过配置job,利用snmp_export读取设备监控信息. 指标(Metric)类型 Counter 计数器,从数据0开始累计计算. 理想状态会永远增长. 累计计算请求次数等 Gauges 瞬时状态的值. 可以任意变化的数值，适用 CPU 使用率 温度等 Histogram 对一段时间范围内数据进行采样，并对所有数值求和与统计数量、柱状图. 某个时间对某个度量值，分组，一段时间http相应大小，请求耗时的时间。 Summary 同样产生多个指标，分别带有后缀_bucket(仅histogram)、_sum、_count Histogram和Summary都可以获取分位数。通过Histogram获得分位数，要将直方图指标数据收集prometheus中， 然后用prometheus的查询函数histogram_quantile()计算出来。 Summary则是在应用程序中直接计算出了分位数。Histograms and summaries中阐述了两者的区别，特别是Summary的的分位数不能被聚合。注意，这个不能聚合不是说功能上不支持，而是说对分位数做聚合操作通常是没有意义的。LatencyTipOfTheDay: You can’t average percentiles. Period中对“分位数”不能被相加平均的做了很详细的说明：分位数本身是用来切分数据的，它们的平均数没有同样的分位效果。 主要我们监控用到最上面两种,下面两种类型目前我没有接触,上面这段文字与介绍引用自lijiaocn 安装Prometheus本次搭建利用docker方式.整体搭建完成需要两个容器.暂不配置告警相关,只做监控数据 前提 搭建位置: /home/aLong/prometheus/ 环境:docker19.03.1 需要指定版本请查阅官方文档. 系统:centos7 准备工作Prometheus的配置文件: prometheus.yml我们建立在搭建位置的根下: touch prometheus.yml在配置文件中加入测试演示配置1234567891011121314global: scrape_interval: 15s scrape_timeout: 10s evaluation_interval: 15sscrape_configs:- job_name: prometheus honor_timestamps: true scrape_interval: 5s scrape_timeout: 3s metrics_path: /metrics scheme: http static_configs: - targets: - localhost:9090 注意配置文件的格式为yaml,语法问题请参考这里. 安装与运行 通过docker 启动 prometheus.123456docker run -d -p 9090:9090 \\ -v /home/along/prometheus.yml:/etc/prometheus/prometheus.yml \\ --name prometheus \\ prom/prometheus \\ --config.file=/etc/prometheus/prometheus.yml \\ --web.enable-lifecycle –web.enable-lifecycle 启用远程热加载配置文件curl -X curl -X POST http://IP:9090/-/reload 验证服务访问 http://IP:9090 会进入简单webUI界面中.这是prometheus的web界面. 里面看到一些信息和监控数据.可以展示图表. 点击 Status-&gt;Target 可以看到监控的设备信息. 访问http://IP:9090/metrics 可以看到监控数据. 到这里,Prometheus已经安装成功,并监测到本机数据. Grafana安装 Grafana是用于可视化大型测量数据的开源程序，它提供了强大和优雅的方式去创建、共享、浏览数据。Dashboard中显示了你不同metric数据源中的数据。Grafana最常用于因特网基础设施和应用分析，但在其他领域也有用到，比如：工业传感器、家庭自动化、过程控制等等。Grafana支持热插拔控制面板和可扩展的数据源，目前已经支持Graphite、InfluxDB、OpenTSDB、Elasticsearch、Prometheus等 docker run -d -p 3000:3000 --name grafana grafana/grafana执行后,通过http:IP:3000 访问grafana.缺省账号密码admin 进入后会有首页的一个引导.添加数据源,选择prometheus.之后可以看到默认的模板上会有数据. 通过官网查询模板插件.导入到系统中.自定义模板选择需要的数据来展示,这里我还没玩6,暂不多说了. 参考https://grafana.com/docs/https://prometheus.io/docs/introduction/overview/https://www.hi-linux.com/posts/25047.html#%E5%AE%89%E8%A3%85prometheushttps://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2018/08/03/prometheus-usage.html#metric%E7%B1%BB%E5%9E%8B","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/categories/Prometheus/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"http://blog.51ai.vip/tags/Prometheus/"},{"name":"Grafana","slug":"Grafana","permalink":"http://blog.51ai.vip/tags/Grafana/"}]},{"title":"Centos5不升级内核更新","slug":"Centos5不升级内核更新","date":"2019-08-23T09:37:03.000Z","updated":"2019-08-23T09:50:55.889Z","comments":true,"path":"2019/08/23/Centos5不升级内核更新/","link":"","permalink":"http://blog.51ai.vip/2019/08/23/Centos5不升级内核更新/","excerpt":"","text":"前提公司需要环境Centos5, 又不能升级内核. 查了一下 大概是 需要 yum –exclude=kernel* update 或者修改 yum.conf 测试一下 出现一个问题:123456Loaded plugins: fastestmirror, securityLoading mirror speeds from cached hostfileYumRepo Error: All mirror URLs are not using ftp, http[s] or file. Eg. Invalid release/removing mirrorlist with no valid mirrors: /var/cache/yum/base/mirrorlist.txtError: Cannot find a valid baseurl for repo: base 根据查询到的信息是,没有正常的源. 解决问题 根据网上的源地址 修改一下:位置: /etc/yum.repos.d/CentOS-Base.repo 修改内容:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[base]name=CentOS-5.11 - Base#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=osbaseurl=http://vault.centos.org/5.11/os/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#released updates[updates]name=CentOS-5.11 - Updates#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=updatesbaseurl=http://vault.centos.org/5.11/updates/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#packages used/produced in the build but not released[addons]name=CentOS-5.11 - Addons#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=addonsbaseurl=http://vault.centos.org/5.11/addons/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#additional packages that may be useful[extras]name=CentOS-5.11 - Extras#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=extrasbaseurl=http://vault.centos.org/5.11/extras/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#additional packages that extend functionality of existing packages[centosplus]name=CentOS-5.11 - Plus#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=centosplusbaseurl=http://vault.centos.org/5.11/centosplus/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5#contrib - packages by Centos Users[contrib]name=CentOS-5.11 - Contrib#mirrorlist=http://mirrorlist.centos.org/?release=5.11&amp;arch=$basearch&amp;repo=contribbaseurl=http://vault.centos.org/5.11/contrib/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5 之后 再使用上面的yum 去更新,发现yum 语句是有问题的. 正确的命令是: yum --exclude=kernel\\* update 或者 yum -x &#39;kernel*&#39; update 确认是否生效首先 yum update 内容可以看到 安装内容中 包含 ‘kernel’ 信息. 之后 执行上句命令后,可以看到 更新信息里没有 ‘kernel’ . 最后可以确定,这个方案是有效的.","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Centos5","slug":"Centos5","permalink":"http://blog.51ai.vip/tags/Centos5/"}]},{"title":"Laradock安装与使用","slug":"Laradock安装与使用","date":"2019-08-15T02:01:03.000Z","updated":"2019-08-22T04:04:42.832Z","comments":true,"path":"2019/08/15/Laradock安装与使用/","link":"","permalink":"http://blog.51ai.vip/2019/08/15/Laradock安装与使用/","excerpt":"","text":"Laradock 安装与使用官网 GitHub: https://github.com/laradock/laradock 要求 Git Docker &gt;= 17.12 项目的位置 已有项目情况: git submodule add https://github.com/Laradock/laradock.git 克隆到项目根目录. 结构 : project-a laradock-a project-b laradock-b 没有项目情况: git clone https://github.com/laradock/laradock.git 克隆后,在同级部署项目. laradock project-x project-y 启动环境clone下来还没有生成. 进入laradock目录,编辑Web服务器站点配置. cp env-exalpme .env环境是laradock环境,里面可以对相应的版本,配置进行修改.例如指定mysql版本为5.7 ,vim .env ,搜索到mysql部分, 修改MYSQL_VERSION=5.7.26 保存退出.(这里还没生成容器前可以统一配置好需要的环境,再生成容器.) 例如我们需要启动环境需要 mysql,redis,nginx. 执行 docker-compose up -d nginx mysql redis 经过漫长等待后,可以得到我们想要的环境,通过 docker ps 或者 docker-compose ps 查看容器. 如果先生成容器,在之后编辑环境时,需要停掉容器,修改完 build之后 再start 容器.例如修改nginx: docker-compose stop nginx 修改.env 或者 nginx conf docker-compose build nginx (完全重建,加参数: –no-cache) docker-compose start nginx Nginx 配置项目我们再laradock中,进入nginx/sites/ 下.复制laravel.conf.example 命名为我们的项目. cp laravel.conf.example Myblog.conf 我们在Myblog.conf 配置nginx 具体信息.这里与配置Vhost一样的操作. 修改完成后,需要build nginx(重建nginx容器). 项目配置数据库laravel项目, .env 中 此项需要改为DB_HOST=mysql,其他参数按照容器mysql配置账号密码等.Redis 修改类似. 项目执行php artisan 方式在laravel 需要执行 php artisan命令时,我们进入到workspace容器, docker-compose exec workspace bash 进入workkspace后,就可以像以前一样进入项目目录中可以执行. 也可以通过开启ssh.连接workspace 执行. 关闭所有正在运行的容器docker-compose stop 删除所有现有容器docker-compose down 其他内容请详见手册吧","categories":[{"name":"Laravel5","slug":"Laravel5","permalink":"http://blog.51ai.vip/categories/Laravel5/"}],"tags":[{"name":"Laravel","slug":"Laravel","permalink":"http://blog.51ai.vip/tags/Laravel/"},{"name":"docker","slug":"docker","permalink":"http://blog.51ai.vip/tags/docker/"}]},{"title":"SwitchHosts管理编辑hosts工具","slug":"SwitchHosts管理编辑hosts工具","date":"2019-08-14T01:41:55.000Z","updated":"2019-08-22T03:49:47.910Z","comments":true,"path":"2019/08/14/SwitchHosts管理编辑hosts工具/","link":"","permalink":"http://blog.51ai.vip/2019/08/14/SwitchHosts管理编辑hosts工具/","excerpt":"","text":"管理Hosts工具 SwitchHosts地址: SwitchHosts 开发工程中,针对不同项目设置不同的域名. 办法很多,例如直接编辑hosts文件,通过环境工具提供的功能设置等. 现在要安利一款便捷实用的工具. SwitchHosts!! 为什么,首先这工具是多平台支持的,我们可以在不同系统中使用.如果之前是靠编辑hosts文件的话,那不同的hosts位置还需要记忆一下,当然这也算不了什么难事. 他的有点不在于能简单编辑hosts文件,也有之前的记录,还可以通过url来读取云端的hosts信息.导入导出功能等. 总之又可以偷懒了. 主界面: 我们可以编辑不同host 分组,使用时打开开关按钮即可使用.示例中使用的My hosts中的配置 配置界面: 支持中文,主题黑白两色.","categories":[{"name":"Tools","slug":"Tools","permalink":"http://blog.51ai.vip/categories/Tools/"}],"tags":[{"name":"hosts","slug":"hosts","permalink":"http://blog.51ai.vip/tags/hosts/"}]},{"title":"VMware安装MacOS系统","slug":"VMware安装MacOS系统","date":"2019-08-12T03:29:38.000Z","updated":"2019-08-22T04:05:48.126Z","comments":true,"path":"2019/08/12/VMware安装MacOS系统/","link":"","permalink":"http://blog.51ai.vip/2019/08/12/VMware安装MacOS系统/","excerpt":"","text":"虚拟机安装 macOS准备工作: VM关闭进程,利用macOS Unlocker修改VM使其能安装macOS系统, 执行程序 win-install.cmd 使用管理员权限运行脚本. 准备好macOS镜象. 利用VM创建虚机,系统类型选择macOS,版本号选择与下载的镜象版本相同. 装系统: 启动虚拟机,并通过cdrom加载镜象. 首次安装需要先利用系统内硬盘工具格式化硬盘,之后利用安装工具进行系统安装. 异常问题: 开启虚拟机弹出错误:vcpu-0 错误. 修改虚机镜象文件.vmx 在smc.present = “TRUE”下面插入一行代码: smc.version = 0 不能正常登陆APPID 需要修改虚拟机,利用Chameleon Wizard 伪造设备信息. 保存 生成的信息 去修改镜象所在文件下的.vmx 修改 board-id.reflectHost = “TRUE” 为FALSE,并在下面插入需要的伪造设备信息例子: board-id = “Mac-94245B3640C91C81”hw.model.reflectHost = “FALSE”hw.model = “MacBook Pro”serialNumber.reflectHost = “FALSE”serialNumber = “C02JJ8B3DH2G”smbios.reflectHost = “FALSE” 这段信息中的board-id 与 serialNumber 不要与例子的相同.其他可以参考.最后保存,重启. 重启之后尝试是否可以登陆市场.","categories":[{"name":"MacOs","slug":"MacOs","permalink":"http://blog.51ai.vip/categories/MacOs/"}],"tags":[{"name":"VM","slug":"VM","permalink":"http://blog.51ai.vip/tags/VM/"},{"name":"MacOs","slug":"MacOs","permalink":"http://blog.51ai.vip/tags/MacOs/"}]},{"title":"数据库迁移","slug":"Laravel5数据库迁移","date":"2019-07-26T06:30:25.000Z","updated":"2019-08-22T04:05:48.182Z","comments":true,"path":"2019/07/26/Laravel5数据库迁移/","link":"","permalink":"http://blog.51ai.vip/2019/07/26/Laravel5数据库迁移/","excerpt":"","text":"Laravel5 数据库迁移笔记 创建迁移文件 命令: make:migration 举例: php artisan make:migration create_users_table --create=users 生成位置: 项目/database/migrations/下 文件名已时间开头,后面是自己创建迁移文件名字. –creat 指定数据库中表的名字 编辑迁移文件 打开迁移文件:","categories":[{"name":"Laravel5","slug":"Laravel5","permalink":"http://blog.51ai.vip/categories/Laravel5/"}],"tags":[{"name":"Laravel","slug":"Laravel","permalink":"http://blog.51ai.vip/tags/Laravel/"}]},{"title":"Composer笔记","slug":"Composer笔记","date":"2019-07-15T09:24:45.000Z","updated":"2019-08-22T04:04:21.062Z","comments":true,"path":"2019/07/15/Composer笔记/","link":"","permalink":"http://blog.51ai.vip/2019/07/15/Composer笔记/","excerpt":"","text":"composer - laravel5创建laravel项目：conposer create-project laravel/laravel=5.8.* --prefer-dist ./XXX laravel=5.8.* 这里代表要部署5.8中最高版本 –prefer-dist 参数代表优先下载zip 安装vendor:composer install composer install --prefer-dist 更新：composer update composer版本更新：composer self-update 利用composer 创建laravel控制器：php artisan make:controller HomeController 会在http下 创建一Home的控制器 如果存在分目录情况，需要指定目录：php artisan make:controller Home/HomeController Laravel config:编写一些类的别名，controller中 use 简短的别名为目的。 位置：config/app 存在一数组 aliases 在里面添加 创建模型：创建一个user 的model php artisan make:model User 指定目录加入目录即可 获取项目路由：php artisan route:list composer在项目中安装三方库时候出现报错：执行命令： composer Install 返回错误： Your requirements could not be resolved to an installable set of packages. 解决： 使用 composer install --ignore-platform-reqs 命令设置忽略版本匹配然后再进行安装你所需要的composer包。","categories":[{"name":"Composer","slug":"Composer","permalink":"http://blog.51ai.vip/categories/Composer/"}],"tags":[{"name":"Composer","slug":"Composer","permalink":"http://blog.51ai.vip/tags/Composer/"}]},{"title":"无版权素材站点","slug":"无版权素材站点","date":"2019-06-27T01:58:04.000Z","updated":"2019-08-22T03:51:10.868Z","comments":true,"path":"2019/06/27/无版权素材站点/","link":"","permalink":"http://blog.51ai.vip/2019/06/27/无版权素材站点/","excerpt":"","text":"最近找素材收集一些站点无版权对于我们来说可以放心使用 列表如下： http://www.pexels.com/ http://www.gratisography.com/ https://visualhunt.com/ http://finda.photo http://cupcake.nilssonlee.se/ https://www.photock.jp/ http://pngimg.com/ http://www.designerspics.com http://kaboompics.com/ https://pixabay.com/ https://visualhunt.com/ http://finda.photo http://www.freemagebank.com/ https://stocksnap.io/ http://picjumbo.com/ http://stokpic.com/ https://cn.freeimages.com/ http://www.imcreator.com/free https://www.piqsels.com/zh https://magdeleine.co/browse/ https://colorhub.me/ https://picjumbo.com/ http://streetwill.co/ https://www.foodiesfeed.com/ http://www.peakpx.com/ http://www.polayoutu.com/collections https://negativespace.co/ https://freeforcommercialuse.net/ https://mmtstock.com/","categories":[{"name":"Tools","slug":"Tools","permalink":"http://blog.51ai.vip/categories/Tools/"}],"tags":[{"name":"素材","slug":"素材","permalink":"http://blog.51ai.vip/tags/素材/"}]},{"title":"Hexo笔记","slug":"Hexo笔记","date":"2019-06-04T02:46:48.000Z","updated":"2019-08-22T04:04:21.546Z","comments":true,"path":"2019/06/04/Hexo笔记/","link":"","permalink":"http://blog.51ai.vip/2019/06/04/Hexo笔记/","excerpt":"","text":"多tag文章中 多tag时,无法直接, 空格这种. 方式一: tags: [tag1,tag2] 方式二:123tags:- tag1- tag2","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://blog.51ai.vip/categories/Hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://blog.51ai.vip/tags/hexo/"}]},{"title":"Python建立SocketSSL连接","slug":"Python建立SocketSSL连接","date":"2019-06-04T02:23:11.000Z","updated":"2019-08-22T04:05:48.241Z","comments":true,"path":"2019/06/04/Python建立SocketSSL连接/","link":"","permalink":"http://blog.51ai.vip/2019/06/04/Python建立SocketSSL连接/","excerpt":"","text":"Python Socket连接5月中旬遇到一个功能,需要利用Python建立Socket tcp连接,于设备通讯发送相关数据. 这块没接触,Python也是hello world水平. 赶紧恶补一下: Socket是网络编程的一个抽象概念。 通常我们用一个Socket表示“打开了一个网络链接”，打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型。 服务端我也不知道什么样,这里只记录客户端的相关. 这里我们得到一个文档说,需要建立socket SSL 连接,通过XML格式发送数据. 非ssl的socket:1234567import socket# 创建一个socket:s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 建立连接:s.connect(('192.168.1.230', 80)) SSL socket:端口是3344,ssl跳过验证,如果验证参数需要修改.123456789import socket s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) c = ssl.wrap_socket(s, cert_reqs=ssl.CERT_NONE) try: c.connect(('192.168.1.230', '3344'))except: return 2 这下与那台设备可以正常通讯了,后面实现具体功能就ok了.","categories":[{"name":"Python","slug":"Python","permalink":"http://blog.51ai.vip/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.51ai.vip/tags/Python/"},{"name":"Socket","slug":"Socket","permalink":"http://blog.51ai.vip/tags/Socket/"}]},{"title":"Ubutun16.04安装Python","slug":"Ubutun16-04安装Python","date":"2019-05-24T03:17:59.000Z","updated":"2019-08-22T04:05:48.072Z","comments":true,"path":"2019/05/24/Ubutun16-04安装Python/","link":"","permalink":"http://blog.51ai.vip/2019/05/24/Ubutun16-04安装Python/","excerpt":"","text":"目的安装python3.7.3安装pip 准备工作 系统内置python2.X,去除默认python的软链, sudo rm /usr/bin/python 安装一些软件包&amp;软件包保持最新状态. sudo apt-get update sudo apt-get install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget 安装Python通过编译安装python 默认我下载在home里, cd 下载新python文件, wget https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz 解压文件, tar zxf Python-3.7.3.tgz 把这个文件拷贝到放置的位置. 这里我放到/usr/local/python mkdir -p /usr/local/python 进入这个目录, 执行 ./configure --enable-optimizations之后执行 sudo make -j 8 这里8根据设备cpu核心数来的,不知道你可以写1(手动滑稽) make之后 该 make install 嘛? NO! 是 sudo make altinstall 装完之后, 可以尝试 python –version 看看有没有, 如果没有或者版本不对.可能是准备里你没有删除 /usr/bin/python 或者这个不存在.需要手动添加一下,我这个是没有给我创建成功. sudo ln -s /usr/local/Python-3.7.3/python /usr/bin/python 这里版本是3.7.3版本的python已经好了,但我发现没有pip.那我只好装一下pip. 安装pip同样在home目录下载:curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py 下载完成后, 执行 python get-pip.py我遇到一个问题是: Command ‘lsb_release -a’ returned non-zero exit status 1查了一下,大概意思是lsb_release上的问题,这里python2.X用到的(Ubutun自带2.X),那我解决办法是干掉他 sudo rm -f /usr/bin/lsb_release 重新执行上面的命令,ok 已经安装上pip. 到此结束.","categories":[{"name":"Python","slug":"Python","permalink":"http://blog.51ai.vip/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.51ai.vip/tags/Python/"},{"name":"Ubutun","slug":"Ubutun","permalink":"http://blog.51ai.vip/tags/Ubutun/"}]},{"title":"Go学习笔记","slug":"Go学习笔记","date":"2019-05-15T03:05:52.000Z","updated":"2019-08-22T04:04:21.387Z","comments":true,"path":"2019/05/15/Go学习笔记/","link":"","permalink":"http://blog.51ai.vip/2019/05/15/Go学习笔记/","excerpt":"","text":"变量var 声明,支持类型判断. var name string string类型 name var s string 值初始化 var age = 20 age 类型自动推断 height := 165 简短声明(仅限函数使用) i,j,k := 3.8,true,100 声明一组变量 _, res := 123,321 _特殊变量名,赋予他的值会被丢弃 常量const 声明 const Pi = 3.14 声明一个常量Pi 1234const( apple = &quot;fruit&quot; banana ) banana 常量未定义初始化值会与apple值相同 数据类型boolean,整型,浮点型,字符串,错误 布尔 bool 初始化默认fasle 整型 int8,int16,int32,int64 (有符号) uint8(byte),uint16,uint32(rune),uint64 (无符号) uintptr byte,rune 与uint8,uint32别名 整形初始化默认值0 浮点型 float32,float64(默认浮点类型) complex64,complex128 float32,float64 初始化默认值0 字符串 双引号或,UTF8编码,\\转义 初始化默认值”” 修改需要转换类型为 rune或byte 操作后再转换 数组 长度非负整数 var arr = [10]int{1,2,3,4} 声明数组 切片 slice 切片默认初始化前nil s1 := make([]int,3,5) 声明切片 append() 尾部追加元素 切片长度是包含的元素个数, 容量是能存储的元素个数. Map kV结构集合 1234m := make(map[string]int) &#123; &quot;blue&quot;: 1, &quot;red&quot;: 2&#125; `delete(m,red)` 删除map中一项 `m[&quot;orange&quot;] = 3` 增加一项 `m[&quot;blue&quot;] = 4` 更新一项 range 遍历map,slice 123for i,v := range m &#123; fmt.Println(i,v)&#125; 函数1234func sub(x,y int) (z int) &#123; z = x - y return z&#125; 声明一个方法sub,参数x,y为int型, z返回参数 int型 函数无返回值可不声明,参数也可是函数. 可以传指针或传引用操作 ...int 表示传递变长的参数 defer 关键字 在函数最后执行动作的声明(延迟代码) 局部函数声明修改不影响全局,若全局有同名变量时,内部赋值会改变全局变量(非声明). 方法方法是特殊的函数,区别于方法有前置实例接收参数(receiver) 接口一种抽象的类型 1234type I interface &#123; Get() int Put(int)&#125; 声明时,不能有字段,不能自定义方法,只声明方法,不实习现. 12345//实现接口:func f(p I) &#123; fmt.Println(p.get()) p.Out(1)&#125; 接收一个接口类型作为参数 p实现了接口I,Get(),Put()方法.","categories":[{"name":"GO","slug":"GO","permalink":"http://blog.51ai.vip/categories/GO/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://blog.51ai.vip/tags/Go/"}]},{"title":"redis笔记","slug":"redis笔记","date":"2019-04-25T09:12:52.000Z","updated":"2019-08-22T04:05:47.957Z","comments":true,"path":"2019/04/25/redis笔记/","link":"","permalink":"http://blog.51ai.vip/2019/04/25/redis笔记/","excerpt":"","text":"redis笔记单进程,默认16库, select N 切换库 flushdb 清空库 类型 string 字符串 list 列表 set 集合 sorted set有序集合 hash哈希 一个字符串支持512M 有序集合 每个元素会关联一个double类型分数。成员唯一，分数可以重复。 常用命令key：keys * exists key move key db 移除key 从库中 expire key 为key 设置过期时间 ttl key 查看多少秒过期，-1 永不过期， -2已过期 type key 查看类型 del key 删除 string：getrange key 0-N setrange key 0-N XXX 获取字符串范围内容， 设置范围内为XXX setex 设置生命值多少秒 setnx key 设置一个不存在的key mset mget msetnx list：lpush rpush lrange lpop rpop lindex llen lrem key 2 value 删除2个value ltrim key 0-N 截取并复制给key （其他的删除了） rpoplpush 弹出前面key的值 加入后面的key中 lset key index value 设置key中 index下标的值 linsert key before/afrer value1 value2 key中1值得前面后后面加入2值 set：sadd key value 添加到key集合 smembers key 查询集合 sismember key m 查询m是否在key集合中 scard key 集合ket的基数 spop key 随机移除一个元素并返回元素的值 srem key m 移除m从key的集合中 smove K1 K2 m 将k1的m一刀k2里 sinter key1 key2 交集 sunion key1 key2 并集 sdiff key1 key2 差集 hash：hset user name ali hset user age 33 设置user数据 hget user name 获取user.name hmset human name tom age 44 设置多数据 hmget human name age 获取多数据 hgetall human hdel human name 删除name hlen human 长度 hexists human age 是否存在 hkeys human 获取所有key hvals human 获取所有value hincrby hincrbyfloat hsetnx 不存在添加 zset：zadd key value：score 设置值的分数 zrange key zrangebyscore key min max （不包含 limit 升序 zrevrangebyscore 降序 zrem key value zcount key min max 范围内多少个 zscore key m 返回key 中m的分数值 zrevrange key start stop 降序展示 持久化：rdb aof rdb 快照方式定期生成临时文件，从临时文件替换上次持久化的文件。数据不是非常敏感。 dump.rdb dump.rdb 关机会清空文件，备份需要导出到另一台机器。 设备启动会去读取domp.rdb来恢复数据（文件名可以设置）。 关闭rdb 设置save为空 save命令 bgsave后台异步快照 备份到dump.rdb 优势： 适合大规模莫恢复，完整性和一致性要求不高。 劣势： 意外down 最后一次备份不到。内存被克隆一份，2倍的性能膨胀。 aof 日行形式记录每个写操作，将所有写指令记录。 appendonly yes 开启 注意flushdb all 这些东西也会记录操作。 同时存在两种备份，优先恢复aof文件，如果aof失败， 导入rbd备份数据。 aof文件损毁或异常时， 通过redis-check-aof程序修复后再恢复。 配置：appendfsync always/everysec/no 同步设置 rewrite： aof 采用文件追加方式，记录文件会越来越大，重写机智，aof 文件大小超过阈值时，会启动aof文件的内容压缩，只保留可恢复的最小指令。默认配置64M 事务： mulit 开启 语句 exec执行， discard 取消 语法错误时，全部没执行，如果设置错误，其他执行，错误的不执行。 监控 锁 乐观锁 悲观锁: 悲观锁，锁表。 乐观锁，行信息版本更新。 谁先提交谁成功。 wacth 监控字段，执行事务，如果监控字段未出现变化，事务执行成功。 复制机制： master 写 slave读 配置slave为主 slaveof 主库id 端口 info replication 查看信息 从机不能写数据 方式 1主机 多从机 主机down，从机待命。主机启动，从机继续同步主机。 从机端开，会变成master，除非配置文件规定。否则需要 slaveof 重新顶可以。 主机down后，如果从机某台执行 slaveof no one ，使当前从库变主库。 方式2 主机-&gt;从机-&gt;从机 相连 方式3 哨兵 监控主机是否down，down后根据投票选出从机转换主库。 配置中添加 sentinel.conf ，编写配置： sentinel monitor 主机配置 地址 端口 1 1标识投票 启动哨兵：redis-sentinel 哨兵配置","categories":[{"name":"Redis","slug":"Redis","permalink":"http://blog.51ai.vip/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://blog.51ai.vip/tags/redis/"}]},{"title":"gulp笔记","slug":"gulp笔记","date":"2019-04-22T10:08:54.000Z","updated":"2019-08-22T04:02:33.463Z","comments":true,"path":"2019/04/22/gulp笔记/","link":"","permalink":"http://blog.51ai.vip/2019/04/22/gulp笔记/","excerpt":"","text":"gulpgulp.js是一个前端构建工具。 安装 npm 安装全局gulp，npm install -g gulp。（如果没有梯子，最好安装下cnpm）cnpm 安装 npm install -g cnpm --registry=https://registry.npm.taobao.org安装完cnpm，下面所有npm操作替换cnpm 执行即可。 进入项目，初始化（npm init） 项目安装gulp，项目文件夹下，npm install --save-dev gulp。 (–save-dev 加入此项目依赖中，不需要可取消这个参数) 项目根创建gulpfile.js文件，文件内创建任务测试。 1234var gulp = require(&apos;gulp&apos;);gulp.task(&apos;default&apos;,function()&#123; console.log(&apos;hello world!&apos;);&#125;); 运行 gulp，可以看到默认执行，输出 hello world! 。测试成功。 gulp API上面运行 gulp 执行default ，这个是gulp API。 [文档](https://www.gulpjs.com.cn/docs/api/) gulp工作方式gulp.src 获取文件流,通过pipe方法导入到插件，插件处理的流通过pipe方法导入 gulp.dest中, gulp.dest 输出目标文件。 gulp srcgulp.src(globs[, options]) 输出（Emits）符合所提供的匹配模式（glob）或者匹配模式的数组（array of globs）的文件。 将返回一个 Vinyl files 的 stream 它可以被 piped 到别的插件中。 文档这意思看着有点费劲，理解为获取文件路径。gulp通过这个方法获取到处理的文件流。 参数： globs 文件匹配模式，匹配文件路径，文件名。 类型： string array options 额外可选参数 类型： object 额外参数需要看手册 gulp.destgulp.dest(path[, options]) 能被 pipe 进来，并且将会写文件。并且重新输出（emits）所有数据，因此你可以将它 pipe 到多个文件夹。如果某文件夹不存在，将会自动创建它。 理解为写文件，写入path路径文件。 参数： path 文件写入路径 类型：string function options 额外可选参数 类型：object gulp.taskgulp.task(name[, deps], fn) 定义一个使用 Orchestrator 实现的任务（task）。 用来定义任务，内部使用的是Orchestrator。 参数： name 任务名字 deps 是当前任务需要的其他任务，一个数组。依赖任务，先于此任务执行。 类型：array fn 该函数定义任务所要执行的一些操作，把任务要执行的代码写在里面。 gulp.watchgulp.watch(glob[, opts], tasks)gulp.watch(glob[, opts, cb]) 监视文件，并且可以在文件发生改动时候做一些事情。 参数： glob 文件匹配模式 类型 string array opts 可选配置 类型 object tasks 文件变动后执行的任务 类型 array cb 一个函数，文件发生变化时调用的函数。 类型 function Glob 匹配模式 (node-glob）参考语法 123456789101112131415161718192021222324252627282930匹配符 说明 * 匹配文件路径中的0个或多个字符，但不会匹配路径分割符， 除非分隔符出现在末尾 ** 匹配路径的0个会多个目录 及子目录 需要单独出现， 即他左右不能有其他的东西了如果出现在末尾，也能匹配文件 ？ 匹配文件路径中的一个字符（不能匹配路径分割符/） [...] 匹配方括号中 出现字符的任意一个，当方括号中第一个字符为^或!时， 则表示不匹配方括号中出现字符中的任意一个， 类似于js中正则表达式中的用法 !(pattern|pattern|pattern) 匹配任何与括号中给定的任意模式都不匹配 ？(pattern|pattern|pattern) 匹配括号中给定的任意模式0次或1次 +(pattern|pattern|pattern) 匹配括号中的至少一次 *(pattern|pattern|pattern) 匹配括号中给定的任意模式0次或多次 @(pattern|pattern|pattern) 匹配括号中 给定的任意模式一次 eg：glob 匹配 |能匹配 a.js,x.y,abc,abc/,但不能匹配a/b.js| |.* a.js,style.css,a.b,x.y //*.js 能匹配 a/b/c.js,x/y/z.js,不能匹配a/b.js,a/b/c/d.js ** 能匹配 abc,a/b.js,a/b/c.js,x/y/z,x/y/z/a.b,能用来匹配所有的目录和文件 a/**/z 能匹配 a/z,a/b/z,a/b/c/z,a/d/g/h/j/k/z a/**b/z 能匹配 a/b/z,a/sb/z,但不能匹配a/x/sb/z,因为只有单**单独出现才能匹配多级目录 ?.js 能匹配 a.js,b.js,c.js a?? 能匹配 a.b,abc,但不能匹配ab/,因为它不会匹配路径分隔符 [xyz].js 只能匹配 x.js,y.js,z.js,不会匹配xy.js,xyz.js等,整个中括号只代表一个字符 [^xyz].js 能匹配 a.js,b.js,c.js等,不能匹配x.js,y.js,z.js 多种匹配模式时，使用数组gulp.src([&#39;js/*.js&#39;,&#39;css/*.css&#39;,&#39;*.html&#39;]) 数组中可以用 ！ 排除(放在数组第一个无效)gulp.src([*.js,&#39;!b*.js&#39;]) 编写一个任务常用到压缩，写个压缩demo。目录，根目录下有两个文件夹，dist空文件，src目录,src/js文件夹2个文件，common.js,demo.js。任务目标，将js目录下的.js文件，压缩合并为new.min.js。之后将合并压缩的文件保存到dist/js/。 我们在初始化后的项目中，先安装所需插件，gulp-rename（重命名插件）,gulp-uglify（压缩js插件），gulp-concat（合并文件插件）。npm install gulp-rename gulp-uglify gulp-concat –save-dev 编辑gulpfile.js 123456789101112var gulp=require(&apos;gulp&apos;); var rename= require(&apos;gulp-rename&apos;); //引入插件var uglify= require(&apos;gulp-uglify&apos;);var concat= require(&apos;gulp-concat&apos;); gulp.task(&apos;js&apos;, function()&#123; //创建名为 js的任务 return gulp.src(&apos;src/js/*.js&apos;) //读取文件流 .pipe(concat()) //合并 .pipe(uglify()) //压缩 .pipe(rename(&#123;suffix: &apos;.min&apos;&#125;)) //重命名 .pipe(gulp.dest(&apos;dist/js/&apos;)) //输出到指定路径 &#125;); 文件保存后，命令行执行任务： gulp js 。可以看到Finshed时间，去dist目录可以看到合并压缩的文件已在里面。 gulp插件 CSS压缩 gulp-minify-css Js压缩 gulp-uglify 重命名 gulp-rename 文件合并 gulp-concat 自动加载 gulp-load-plugins less编译 gulp-less sass编译 gulp-sass","categories":[{"name":"前端","slug":"前端","permalink":"http://blog.51ai.vip/categories/前端/"}],"tags":[{"name":"gulp","slug":"gulp","permalink":"http://blog.51ai.vip/tags/gulp/"}]},{"title":"Centos7时间设置","slug":"Centos7时间设置","date":"2019-04-19T03:42:02.000Z","updated":"2019-08-22T04:04:21.439Z","comments":true,"path":"2019/04/19/Centos7时间设置/","link":"","permalink":"http://blog.51ai.vip/2019/04/19/Centos7时间设置/","excerpt":"","text":"Centos7时间相关查看时间datehwclock 硬件时间timedatectl 各时间状态 设置&amp;更新服务时间安装ntpdateyum install utp ntpdate 设置同步ntpdate cn.pool.ntp.org (time.windows.com) 地址看喜好 设置硬件时间hwclock –systohc 设置时区timedatectl set-timezone Asia/Shanghai （上海） timedatectl 很多设置，需要请查相关资料。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Centos7","slug":"Centos7","permalink":"http://blog.51ai.vip/tags/Centos7/"}]},{"title":"Centos7防火墙相关设置","slug":"Centos7防火墙相关设置","date":"2019-04-18T09:44:22.000Z","updated":"2019-08-22T04:04:21.286Z","comments":true,"path":"2019/04/18/Centos7防火墙相关设置/","link":"","permalink":"http://blog.51ai.vip/2019/04/18/Centos7防火墙相关设置/","excerpt":"","text":"Centos7与之前不太一样以前都是用iptables，公司服务器环境事7，凑巧不熟一台新服务。我为了测试，再本地虚机上装了一台。这里默认防火墙是 firewall，其实为了省事还是可以安装一个iptables的。这里学习一下firewall一些操作。 查看防火墙服务状态systemctl status firewalld ####查看f防火墙状态firewall-cmd --state 查看规则firewall-cmd --list-all ####停止&amp;开启防&amp;重启火墙systemctl stop firewalld.servicesystemctl start firewalld.servicesystemctl restart firewalld.service 关闭防火墙systemctl disable firewalld.service 重载防火墙firewall-cmd —reload 查询开放端口firewall-cmd --list-ports 开放一个端口 例如tcp 8010firewall-cmd –zone=public –add-port=80/tcp –permanent –zone #作用域–add-port=8010/tcp #添加端口，格式为：端口/通讯协议–permanent #永久生效，没有此参数重启后失效 查询某端口是否开放(8010)firewall-cmd --query-port=8010/tcp 移除端口规则firewall-cmd --permanent --remove-port=8010/tcp","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Centos7","slug":"Centos7","permalink":"http://blog.51ai.vip/tags/Centos7/"}]},{"title":"Centos7启动等级设置","slug":"Centos7启动等级设置","date":"2019-04-15T08:55:19.000Z","updated":"2019-08-22T04:02:47.204Z","comments":true,"path":"2019/04/15/Centos7启动等级设置/","link":"","permalink":"http://blog.51ai.vip/2019/04/15/Centos7启动等级设置/","excerpt":"","text":"Centos7启动级别启动级别分为7个：0 - 系统停机状态1 - 单用户工作状态2 - 多用户状态（没有NFS）3 - 多用户状态（有NFS）4 - 系统未使用，留给用户5 - 图形界面6 - 系统正常关闭并重新启动 切换启动级别之前一直都是在种端中输入指令 init3 切换启动级别。设置永久启动3级别， vi /etc/inittab 把init3设置默认即可。 centos7 设置出现不同runlevels被targets所取代，即CentOS7采用加载target的方式来替代之前的启动级别。multi-user.target = init3graphical.target = init5我们日常实用图形窗口init5，我们不需要图形，可以切换到init3等启动级别上。systemctl set-default multi-user.target 设置为init3systemctl set-default graphical.target 设置为init5","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Centos7","slug":"Centos7","permalink":"http://blog.51ai.vip/tags/Centos7/"}]},{"title":"Docker常用命令","slug":"Docker常用命令","date":"2019-04-11T07:09:19.000Z","updated":"2019-08-22T04:04:21.335Z","comments":true,"path":"2019/04/11/Docker常用命令/","link":"","permalink":"http://blog.51ai.vip/2019/04/11/Docker常用命令/","excerpt":"","text":"Docker常用命令说常用不如说自己用到的命令。 容器相关学习了一下docker，基础常用命令记录下。 ####docker run/新建并启动容器这个run其实包含两个不走，先执行新建容器(docker create),接着启动容器(docker start)。敲两个是不是有点麻烦吧。 docker run xx [COMMAND] 例子 docker run -it ubuntu:14.04 /bin/bash 这里希望启动一个基于 ubuntu 14.04镜像 来创建一个容器，-t选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上，-i则让容器的标准输入保持打开。更多的命令选项可以通过man docker-run命令来查看。之后命令还有一项，启动一个bash终端。 这条命令涉及到很多知识了。-参数 常用 -i -d -t -p， -d 是否在后台运行，-p 映射到本地主机端口。剩下的看手册来补下。 docker create &amp;&amp; docker start &amp;&amp; docker stop创建，启动，停止。有一个容易停止了，可以用 docker start XX容器 启动。 XX 可以是容器的ID，也可以是name。 docker rm删除一个容器（最好先把这个容器停止了再删除）。-f 可以强制删除。-v 删除与容器关联的卷（如果刚学习还真不知道什么是卷）。 docker attach进入容器，如果开启了一个 -d 后台启动容器。 我们怎么进去看看？ docker attach XX容器这个命令我学习时候用过，感觉有时候不太好使。命令执行完卡那不动。 docker exec可以在容器内直接执行任意命令。docker exec -it xx /bin/bash 这可以进入xx镜像，并打开bash。 相比这个比上面的attach 好多了。 docker ps列出启动中的容器， docker ps -a 列出所有镜像。 ###仓库相关 docker images列出本地镜像文件 docker rmi删除本地镜像文件 docker seach xxx在docker hub查询xxx 镜像 docker pull想不想git？ docker pull xx 可以下载xx镜像到本地。 （还能联想到 push 吧？ commit ？ 这些吧） docker login登陆docker hub docker push推送本地镜像到docker hub上。 数据相关-v在容器内创建数据卷 docker run -d -v /test ubuntu 在此镜像下创建一个test数据卷也可以挂在主机目录为数据卷 docker run -d -v /usr/local/src:/opt/test ubuntu 将本地的/usr/lcoal/src 挂载到此镜象的 /opt/test 作为数据卷。 在本机修改，容器内可以看到。这里可以增加参数来控制读写，默认读写。 volumes-from数据卷容器容器与容器间的数据挂在参数。例如有个容器为 files ，通过另一个 test来挂在files。 docker run -it --volumes-from files --name test ubuntu--name 是为后者容器起名。这个名字叫test 挂在了files 容器的数据。 端口映射，容器互联-p &amp;&amp; -Pdocker run -itd -p 8080:80 --name web nginx:1.15 本机8080端口映射到容器80.-p 需要自己分配端口 -P Docker会随机映射一个49000~49900的端口 docker port查看映射端口配置 link--link参数可以让容器之间安全地进行交互 基本上了解到的命令吧，后续根据搭建环境以及使用中来丰富其他的命令和参数。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.51ai.vip/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.51ai.vip/tags/Docker/"}]},{"title":"Ubutun下安装Docker","slug":"Ubutun下安装Docker","date":"2019-04-04T06:57:16.000Z","updated":"2019-08-22T04:05:47.895Z","comments":true,"path":"2019/04/04/Ubutun下安装Docker/","link":"","permalink":"http://blog.51ai.vip/2019/04/04/Ubutun下安装Docker/","excerpt":"","text":"Docker简介 一个能够把开发的应用程序自动部署到容器的开源引擎三大概念：镜像（Image）容器（Container）仓库（Repository） 具体信息请参考官方。官方概述（养成看文档习惯） 安装环境Ubuntu 16.04 LTS Docker安装根据官方doc安装。官方doc1.如果你之前装过，命令卸载。sudo apt-get remove docker docker-engine docker.io containerd runc 2.更新包索引apt-get update 3.安装包以允许apt通过HTTPS使用存储库:sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common（斜线换行，一条命令） 4.添加Docker的官方GPG密钥:curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo apt-key fingerprint 0EBFCD88 5.使用以下命令设置稳定存储库。要添加 夜间或测试存储库，请在下面的命令中的单词后添加单词nightly或test（或两者）stable。$ sudo add-apt-repository \\ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable&quot; (lsb_release -cs子命令返回Ubuntu发行版的名称) 6.安装最新版本的Docker CE和containerd，或者转到下一步安装特定版本： sudo apt-get install docker-ce docker-ce-cli containerd.io 7.运行hello-world 映像验证是否正确安装了Docker CE: sudo docker run hello-world (执行之后，返回docker的信息) 至此，安装过程是结束了。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.51ai.vip/categories/Linux/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.51ai.vip/tags/Docker/"},{"name":"Ubutun","slug":"Ubutun","permalink":"http://blog.51ai.vip/tags/Ubutun/"}]},{"title":"hexo博客安装与配置","slug":"hexo博客安装与配置","date":"2019-04-01T09:59:31.000Z","updated":"2019-08-22T04:04:21.211Z","comments":true,"path":"2019/04/01/hexo博客安装与配置/","link":"","permalink":"http://blog.51ai.vip/2019/04/01/hexo博客安装与配置/","excerpt":"","text":"wordpress 之后wordpress 使用很方便，但是折腾几次之后。由于一次意外，导致管理者把我的vps被停掉。虽然有些文章还是保留了。但是这次之后感觉自己还是找一个稳妥的家。连接hexo搭建的博客之后，打算自己来折腾一下。 记录笔记环境在windows上写笔记，环境目前是windows下操作。linux，mac系统中需要注意一些细节吧。存在提不到情况，先做好出现问题考虑自行排查。 准备看下hexo的安装提示。 hexo 需要Node.js 和 Git 。 安装 Node.js官网: 官网widows，mac，linux 都有对应的安装方法。根据自己的环境来安装。 安装 Git官网: 官网根据自己环境安装。 安装Hexo通过npm来安装 Hexo。命令: npm install -g hexo-cli什么鬼，通过这个命令发现没有实现正常安装。理由，我们在天朝。解决方式： 替换国内npm源。命令: npm install -g cnpm --registry=https://registry.npm.taobao.org请注意不同系统在操作此命令时，需要一些设置。linux 如果使用下面命令需要自建软链。 cnpm ln -s /yourdir/bin/cnpm /usr/local/npm下一步用cnpm 来安装 Hexo： cnpm install hexo-cli -g验证hexo 是否安装： hexo v 会列出版本信息。 下面使用Hexo来创建blog： 创建项目文件夹。这里开始通过git bash来使用命令行操作。 进入项目文件夹，初始化。 hexo init （这里也可以，通过 hexo init 你的项目文件夹名 结果一样）这里会看到目录有相关文件了。具体这些文件，看下 手册 是什么意思。这时候其实已经是一个博客站点了。 命令 hexo g , hexo s 得到信息：Hexo is running at http：//lcoalhost:4000` 注意4000端口需要未被占用。 访问地址就可以看到初始化的站点了。 （不喜欢默认主题可以修改主题） 写文章写文章需要先创建文档，这个文档默认生成在_post 文件夹下。 命令 hexo new testdoc 得到信息： Created:···path/testdoc.md 文档的位置，需要编辑这个文档来写文章（Markdown文档）。文档写好保存之后。命令 hexo g , hexo s 之后我们访问之 localhost:4000 就能看到自己的新文章了。 推送到Git仓库，在线访问。首先需要一个 GitHub ，注册账号。创建一个与账户名一样的库， 用户名.github.io , 之后在项目文件夹中，编辑 _config.yml 配置文件。 1234deploy: type: git repo: https://github.com/用户名/用户名.github.io.git (我相信你能知道这个地址在哪里) branch: master 之前写过testdoc.md 这个文件。提交到git库上，命令： hexo d , 提交是，会弹出账号密码让你输入。接着得到提示： Deploy done: git。 这里我们就提交到库上了。 （账号密码提交比较麻烦，可以通过配置公钥来解决）这里如果出现错误 Deployer not found：git ，需要安装一下。 命令 npm install hexo-deployer-git --save这时候我们可以通过 用户名.github.io.git 这个地址访问到博客了。（不喜欢这个地址，可以通过域名来绑定） 主题更换默认的主题让我们觉得太不个性化了。还没有能力自己操刀编辑，怎么办？ 建议先看下文档.了解一下,培养看文档习惯. 可以使用别人的主题，官网提供 提供一些，也可以通过网上其他人的推荐来使用自己喜欢的主题。例如在官网地址上看到有一个名字是 Next(很多人有这个,或基于此主题修改). 点击可以语言并且访问.地址 , 我们需要克隆到自己项目下 themes 文件下. 你可以下载zip到自己项目下解压,不过有些麻烦也不够B格.我们使用git操作. 打开gitbash, 进入到自己项目下/themes 命令 git clone https://github.com/theme-next/hexo-theme-next.git . 执行完后,themes 下会有这个文件. 使用next 主题, 需要在 _config.yml 上面设置主题. theme: next 配置主题为next 之后通过命令 hexo g, hexo s. 两个命令后, 登陆localshot:4000 查看一下. 嗯,已经替换成功了. 目前只是替换了主题,主题也是需要配置的,我们需要在 _config.yml 配置菜单等一些参数. 主题相关修改参数配置是需要在 项目/themes/languages/{language}.yml具体配置希望你看下每个主题的README,或者文档来学习着自己修改. 还要涉及到页面的问题,我们之前 hexo new xx文章 ,都是默认_post文件夹下, 如果我们要定义归档,友链,等页面.也是通过new 命令来实现的. 例如: 建立 tags页面 hexo new page tags之后你会看到 项目下/source/ 会出现tags 文件夹,进入里面会有一个index.md .这个文件就是你需要的tags 页面. 域名我们觉得github 这个url不太喜欢,并且也很长.可以配置自己的域名.首先我们需要一个自己的域名,通过万网什么的来购买一个.我是通过阿里云上万网购买的一个域名.这里不详细来说明域名的购买. 万网控制台里面,有域名的功能(例如阿里云,登陆后,控制台-&gt;域名-&gt;点击域名-&gt;域名解析). 在github，xxx.github.io 点击 settingsCustom domain 这里填写你的域名，save。 此处注意：你配置完后，会看到库中存在一个文件，CNANE文件。如果你再次提交新文档，会发现你的配置域名无法访问了！原因：你本地文件没有这个CNAME，通过hexo d 方式 更新库文件后，CNAME没了。通过配置域名后，把这个文件下载到本地项目中，位置请注意：项目/source 下。不然hexo d 不会提交到库中。 如果不搞定这个，那你每次hexo d 之后，都要改一次custom domain。（我想谁也不会每次都这么操作）到这里基本上你这台电脑上，发布你的博客。更新，推送到github都没有问题。还有一个问题就是那么如果我换一台电脑怎么办？ 通过分支来完善博客工作中使用版本控制器，很方便管理项目代码和文件。那么我们这个hexo 博客也需要这种方式来吧本地的hexo 博客项目推送到线上。如果过本地电脑出故障，或者更换电脑等情况下。我们依然可以通过clone到本地，进行发布博客。 克隆博客gitbash clone一份自己的博客(省略命令), 删除克隆后出.git 这个文件外其他文件。把之前本地初始化项目中的文件都复制到此项目中。 新建分支 git branch hexo, git checkout hexo. 两条命令,新建分支,切换至hexo 分支. 在新分支中，提交我们刚才复制过来的文件。 git add --all 提交文件并push到远程。 git commit -m &quot;mybolg files&quot;, git push origin hexo 推送带云端。 这下完成了，不用担心换电脑。换电脑后，clone一下，继续可以发布。ps：git你需要自己装。之后我们一直再这个 hexo 分支就好啦。每次hexo d 之后记得把新文件提交到hexo分支。 add commit push 三步骤不能忘。 配置公钥之前没提到这个，是因为我怕忘记密码，每次都手输入密码。也不是每个人都喜欢我这么操作。那可以选择配置公钥来解决提交时的认证。 gitbash ssh-keygen 生成密钥，注意看信息密钥提示位置。 打开生成目录下的 id_res.pub 这个是公钥。打开复制里面的数据，复制。 需要粘贴到github settings-&gt;SSH and GPG keys 里面。 测试一下配置 gitbash ssh -T git@github.com 得到信息 You’ve successfully authenticated, but GitHub does not provide shell access. 配置正常。 改完这里还不可以，需要配置项目hexo配置文件了，还记得是哪个文件嘛？（ _config.yml）之前我们用的是https，现在我们需要用ssh地址提交了。4.修改 _config.yml 这段配置的 repo地址，看下之前参数和现在参数。 12345deploy: type: git #repo: https://github.com/chenweil/chenweil.github.io.git # https repo: git@github.com:chenweil/chenweil.github.io.git # ssh branch: master 到这里我们已经配置好，我们下次写完文章是 hexo d 不会让你输入密码了。真的不用输入密码了吗? 你可能会遇到问题,怎么还需要认证?(因为我这环境出现了问题)看下错误 :git push origin hexofatal: HttpRequestException encountered.如果你现者句话,那么需要你更新一下Windows的git凭证管理器.管理器地址 到此基本的配置已经完成，文中只是简单的描述了基础工作。再哪方面出现问题需要通过文档和网络来查询问题。第一次接触此框架，还是好好看文档。你通过网络查询的很多结果存在一些问题。例如版本不同，环境不同等。最好的方法还是自己来分析，处理。养成好习惯，戒心浮气躁，坚持自己来解决问题。","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://blog.51ai.vip/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://blog.51ai.vip/tags/Hexo/"}]}]}